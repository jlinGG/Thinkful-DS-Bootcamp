{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Classifier\n",
    "\n",
    "## Description\n",
    "For this project, I will be building a Twitter classifier.  I am pulling the most recent ~3200 tweets from four twitter handles: realDonaldTrump, junstinbieber, hillaryclinton, and katyperry.  I will then be using a variety of supervised and unsupervised models to classify the tweets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "consumer_key = '9SRz5HMehrEVQf2m7AoN4shrq'\n",
    "consumer_secret = 'zZa9j55quKFTmTwm4PKx4B6RUn3OyCsEtVJmvqbLAX9d8K3Adu'\n",
    "access_token = '2801486303-55EJTjYXUPvw5uzXmRQV8wTHDmiLh70BJoASUj9'\n",
    "access_token_secret = 'aRGfnR8N4if56loNt0yhwChXBe61go8qTpEanmXV2RBRp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thank you, yanofsky! Adapted from: https://gist.github.com/yanofsky/5436496\n",
    "\n",
    "def get_all_tweets(screen_names):\n",
    "\n",
    "    #authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    \n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for screen_name in screen_names:\n",
    "        \n",
    "        alltweets = []\n",
    "\n",
    "        #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name ,count=200)\n",
    "\n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "\n",
    "        #save the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "\n",
    "        #keep grabbing tweets until there are no tweets left to grab\n",
    "        while len(new_tweets) > 0:\n",
    "            print(\"getting tweets before %s\" % (oldest))\n",
    "\n",
    "            #all subsiquent requests use the max_id param to prevent duplicates\n",
    "            new_tweets = api.user_timeline(screen_name = screen_name,count=200,max_id=oldest)\n",
    "\n",
    "            #save most recent tweets\n",
    "            alltweets.extend(new_tweets)\n",
    "\n",
    "            #update the id of the oldest tweet less one\n",
    "            oldest = alltweets[-1].id - 1\n",
    "\n",
    "            print(\"...%s tweets downloaded so far\" % (len(alltweets)))\n",
    "\n",
    "        #transform the tweepy tweets into a 2D array that will populate the csv\t\n",
    "        outtweets = [[tweet.user.screen_name, tweet.text] for tweet in alltweets]\n",
    "\n",
    "        df = df.append(pd.DataFrame(data=outtweets)).reset_index(drop=True)\n",
    "        \n",
    "    return df\n",
    "    \n",
    "    print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 985489930343321599\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 972835128056664065\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 961693860916289535\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 949619270631256063\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 938752267611721727\n",
      "...1197 tweets downloaded so far\n",
      "getting tweets before 928769154345324543\n",
      "...1397 tweets downloaded so far\n",
      "getting tweets before 921319017826091007\n",
      "...1596 tweets downloaded so far\n",
      "getting tweets before 914089003745468416\n",
      "...1796 tweets downloaded so far\n",
      "getting tweets before 907579024960098303\n",
      "...1996 tweets downloaded so far\n",
      "getting tweets before 897783159038910465\n",
      "...2196 tweets downloaded so far\n",
      "getting tweets before 889579795176181760\n",
      "...2396 tweets downloaded so far\n",
      "getting tweets before 880017678978736128\n",
      "...2595 tweets downloaded so far\n",
      "getting tweets before 868840252227674112\n",
      "...2795 tweets downloaded so far\n",
      "getting tweets before 854547423464759295\n",
      "...2995 tweets downloaded so far\n",
      "getting tweets before 837987684660412415\n",
      "...3195 tweets downloaded so far\n",
      "getting tweets before 824407390674157567\n",
      "...3220 tweets downloaded so far\n",
      "getting tweets before 822502601304526847\n",
      "...3220 tweets downloaded so far\n",
      "getting tweets before 806933331669454847\n",
      "...397 tweets downloaded so far\n",
      "getting tweets before 771277449648754687\n",
      "...593 tweets downloaded so far\n",
      "getting tweets before 739329762728935423\n",
      "...790 tweets downloaded so far\n",
      "getting tweets before 709938683332272127\n",
      "...989 tweets downloaded so far\n",
      "getting tweets before 686629936975622143\n",
      "...1188 tweets downloaded so far\n",
      "getting tweets before 671794724110508032\n",
      "...1388 tweets downloaded so far\n",
      "getting tweets before 666402468646035455\n",
      "...1588 tweets downloaded so far\n",
      "getting tweets before 663744491489103871\n",
      "...1781 tweets downloaded so far\n",
      "getting tweets before 658593941676257279\n",
      "...1971 tweets downloaded so far\n",
      "getting tweets before 655100293122760703\n",
      "...2169 tweets downloaded so far\n",
      "getting tweets before 644745598516617215\n",
      "...2369 tweets downloaded so far\n",
      "getting tweets before 638949361930518527\n",
      "...2569 tweets downloaded so far\n",
      "getting tweets before 634621465690701823\n",
      "...2769 tweets downloaded so far\n",
      "getting tweets before 626991877665853439\n",
      "...2969 tweets downloaded so far\n",
      "getting tweets before 610314212749914111\n",
      "...3167 tweets downloaded so far\n",
      "getting tweets before 590916763505721343\n",
      "...3167 tweets downloaded so far\n",
      "getting tweets before 907767184608374784\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 795825627840462847\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 794252589294637055\n",
      "...800 tweets downloaded so far\n",
      "getting tweets before 791711031139729407\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 789190569712943107\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 786607322982473727\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 784770142454579199\n",
      "...1600 tweets downloaded so far\n",
      "getting tweets before 782779577240256511\n",
      "...1800 tweets downloaded so far\n",
      "getting tweets before 780594447427960832\n",
      "...2000 tweets downloaded so far\n",
      "getting tweets before 777673718982184963\n",
      "...2200 tweets downloaded so far\n",
      "getting tweets before 775714298966450175\n",
      "...2400 tweets downloaded so far\n",
      "getting tweets before 771472849831878656\n",
      "...2600 tweets downloaded so far\n",
      "getting tweets before 767077465797918722\n",
      "...2800 tweets downloaded so far\n",
      "getting tweets before 763032112689623039\n",
      "...3000 tweets downloaded so far\n",
      "getting tweets before 758863680037466115\n",
      "...3200 tweets downloaded so far\n",
      "getting tweets before 758392712907350015\n",
      "...3203 tweets downloaded so far\n",
      "getting tweets before 758370570069237759\n",
      "...3203 tweets downloaded so far\n",
      "getting tweets before 975576051941236736\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 936682303169945599\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 881292124343357439\n",
      "...796 tweets downloaded so far\n",
      "getting tweets before 872727498022240259\n",
      "...996 tweets downloaded so far\n",
      "getting tweets before 863193438019137535\n",
      "...1194 tweets downloaded so far\n",
      "getting tweets before 856765678396649471\n",
      "...1393 tweets downloaded so far\n",
      "getting tweets before 833678554160304127\n",
      "...1593 tweets downloaded so far\n",
      "getting tweets before 807801171809140735\n",
      "...1793 tweets downloaded so far\n",
      "getting tweets before 785296490617004031\n",
      "...1992 tweets downloaded so far\n",
      "getting tweets before 774718212218851327\n",
      "...2192 tweets downloaded so far\n",
      "getting tweets before 754030603637436415\n",
      "...2388 tweets downloaded so far\n",
      "getting tweets before 677326932350910463\n",
      "...2588 tweets downloaded so far\n",
      "getting tweets before 630853109904973823\n",
      "...2788 tweets downloaded so far\n",
      "getting tweets before 572175171458506751\n",
      "...2983 tweets downloaded so far\n",
      "getting tweets before 532448437384396799\n",
      "...3178 tweets downloaded so far\n",
      "getting tweets before 501837631932862464\n",
      "...3218 tweets downloaded so far\n",
      "getting tweets before 499322307236855809\n",
      "...3218 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "# Getting the most recent 3200 tweets from Donald Trump, Kanye West, Hillary Clinton, \n",
    "#  Taylor Swift\n",
    "tweets = get_all_tweets(['realDonaldTrump','justinbieber','hillaryclinton','katyperry'])\n",
    "\n",
    "#tweets = get_all_tweets(['acupofjoanne'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "realDonaldTrump    3220\n",
       "katyperry          3218\n",
       "HillaryClinton     3203\n",
       "justinbieber       3167\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12808 entries, 0 to 12807\n",
      "Data columns (total 2 columns):\n",
      "0    12808 non-null object\n",
      "1    12808 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 200.2+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.columns = ['screenname','tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screenname</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>RT @WhiteHouse: \"Finally, I want to deliver a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>RT @WhiteHouse: \"At the heart of the Iran deal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Statement on the Iran Nuclear Deal: https://t....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>John Kerry can’t get over the fact that he had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>I will be speaking to my friend, President Xi ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        screenname                                              tweet\n",
       "0  realDonaldTrump  RT @WhiteHouse: \"Finally, I want to deliver a ...\n",
       "1  realDonaldTrump  RT @WhiteHouse: \"At the heart of the Iran deal...\n",
       "2  realDonaldTrump  Statement on the Iran Nuclear Deal: https://t....\n",
       "3  realDonaldTrump  John Kerry can’t get over the fact that he had...\n",
       "4  realDonaldTrump  I will be speaking to my friend, President Xi ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['tweet'] = tweets['tweet'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(tweet):\n",
    "    tweet = re.sub(r'http.*','',tweet)\n",
    "    tweet = re.sub(r'bit/ly.*', \"\", tweet)\n",
    "    tweet = re.sub(r'b\\'', \"\", tweet)\n",
    "    tweet = re.sub(r'b\"', \"\", tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(len(tweets['tweet'])):\n",
    "    tweets['tweet'][r] = text_cleaner(tweets['tweet'][r])\n",
    "\n",
    "#Dropping retweets    \n",
    "tweets = tweets[tweets['tweet'].str.contains(\"RT\") == False].reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screenname</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Statement on the Iran Nuclear Deal:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>John Kerry can’t get over the fact that he had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>I will be speaking to my friend, President Xi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Gina Haspel, my highly respected nominee to le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>I will be announcing my decision on the Iran D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>National Prescription Drug #TakeBackDay number...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>The United States does not need John Kerry’s p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Is this Phony Witch Hunt going to go on even l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Lisa Page, who may hold the record for the mos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Good luck to Ric Grenell, our new Ambassador t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>“The Great Revolt” by Salena Zito and Brad Tod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>The 13 Angry Democrats in charge of the Russia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>The Russia Witch Hunt is rapidly losing credib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>My highly respected nominee for CIA Director, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>To the great people of West Virginia we have, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Thank you Cleveland, Ohio!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Our high level delegation is on the way back f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Just returned home to the beautiful White Hous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Great book just out by very successful busines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>I want to thank all of our friends and patriot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         screenname                                              tweet\n",
       "0   realDonaldTrump               Statement on the Iran Nuclear Deal: \n",
       "1   realDonaldTrump  John Kerry can’t get over the fact that he had...\n",
       "2   realDonaldTrump  I will be speaking to my friend, President Xi ...\n",
       "3   realDonaldTrump  Gina Haspel, my highly respected nominee to le...\n",
       "4   realDonaldTrump  I will be announcing my decision on the Iran D...\n",
       "5   realDonaldTrump  National Prescription Drug #TakeBackDay number...\n",
       "6   realDonaldTrump  The United States does not need John Kerry’s p...\n",
       "7   realDonaldTrump  Is this Phony Witch Hunt going to go on even l...\n",
       "8   realDonaldTrump  Lisa Page, who may hold the record for the mos...\n",
       "9   realDonaldTrump  Good luck to Ric Grenell, our new Ambassador t...\n",
       "10  realDonaldTrump  “The Great Revolt” by Salena Zito and Brad Tod...\n",
       "11  realDonaldTrump  The 13 Angry Democrats in charge of the Russia...\n",
       "12  realDonaldTrump  The Russia Witch Hunt is rapidly losing credib...\n",
       "13  realDonaldTrump  My highly respected nominee for CIA Director, ...\n",
       "14  realDonaldTrump  To the great people of West Virginia we have, ...\n",
       "15  realDonaldTrump                        Thank you Cleveland, Ohio! \n",
       "16  realDonaldTrump  Our high level delegation is on the way back f...\n",
       "17  realDonaldTrump  Just returned home to the beautiful White Hous...\n",
       "18  realDonaldTrump  Great book just out by very successful busines...\n",
       "19  realDonaldTrump  I want to thank all of our friends and patriot..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpful link about disabling piplines: https://spacy.io/usage/processing-pipelines#disabling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenizing all tweets into one text and parsing.\n",
    "nlp = spacy.load('en', disable=['parser'])\n",
    "\n",
    "text = tweets['tweet'].str.cat()\n",
    "text = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse tweets\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "parsed = []\n",
    "\n",
    "for r in tweets['tweet']:\n",
    "    p = nlp(r)\n",
    "    parsed.append(p)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['parsed'] = parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screenname</th>\n",
       "      <th>tweet</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Statement on the Iran Nuclear Deal:</td>\n",
       "      <td>(Statement, on, the, Iran, Nuclear, Deal, :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>John Kerry can’t get over the fact that he had...</td>\n",
       "      <td>(John, Kerry, ca, n’t, get, over, the, fact, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>I will be speaking to my friend, President Xi ...</td>\n",
       "      <td>(I, will, be, speaking, to, my, friend, ,, Pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>Gina Haspel, my highly respected nominee to le...</td>\n",
       "      <td>(Gina, Haspel, ,, my, highly, respected, nomin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "      <td>I will be announcing my decision on the Iran D...</td>\n",
       "      <td>(I, will, be, announcing, my, decision, on, th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        screenname                                              tweet  \\\n",
       "0  realDonaldTrump               Statement on the Iran Nuclear Deal:    \n",
       "1  realDonaldTrump  John Kerry can’t get over the fact that he had...   \n",
       "2  realDonaldTrump  I will be speaking to my friend, President Xi ...   \n",
       "3  realDonaldTrump  Gina Haspel, my highly respected nominee to le...   \n",
       "4  realDonaldTrump  I will be announcing my decision on the Iran D...   \n",
       "\n",
       "                                              parsed  \n",
       "0       (Statement, on, the, Iran, Nuclear, Deal, :)  \n",
       "1  (John, Kerry, ca, n’t, get, over, the, fact, t...  \n",
       "2  (I, will, be, speaking, to, my, friend, ,, Pre...  \n",
       "3  (Gina, Haspel, ,, my, highly, respected, nomin...  \n",
       "4  (I, will, be, announcing, my, decision, on, th...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words\n",
    "Let's use bag of words! For each tweet, we will count how many times each word appears and use those counts as features.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(1000)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(tweets, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = tweets['parsed']\n",
    "    df['text_source'] = tweets['screenname']\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the top 1000 common words in all the tweets.\n",
    "\n",
    "common_words = bag_of_words(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-PRON-',\n",
       " 'be',\n",
       " 'trump',\n",
       " 'not',\n",
       " 'great',\n",
       " 'amp',\n",
       " '\\n',\n",
       " 'the',\n",
       " 'thank',\n",
       " \"'s\",\n",
       " 'good',\n",
       " 'people',\n",
       " 'hillary',\n",
       " 'time',\n",
       " 'president',\n",
       " 'today',\n",
       " 'day',\n",
       " 'go',\n",
       " 'get',\n",
       " 'america',\n",
       " 'love',\n",
       " '\\n\\n',\n",
       " '️',\n",
       " 'year',\n",
       " 'want',\n",
       " 'vote',\n",
       " ' ',\n",
       " 'donald',\n",
       " 'u',\n",
       " 'new',\n",
       " 'come',\n",
       " 'work',\n",
       " 'country',\n",
       " 'big',\n",
       " 'tax',\n",
       " 'like',\n",
       " '’',\n",
       " 'let',\n",
       " 'have',\n",
       " 'make',\n",
       " '❤',\n",
       " 'news',\n",
       " 'woman',\n",
       " 'know',\n",
       " 'this',\n",
       " 'need',\n",
       " 'right',\n",
       " '’s',\n",
       " 'job',\n",
       " 'will',\n",
       " 'say',\n",
       " 'tonight',\n",
       " 'family',\n",
       " 'look',\n",
       " 'a',\n",
       " 'fake',\n",
       " 'american',\n",
       " 'election',\n",
       " '❗',\n",
       " 'help',\n",
       " 'see',\n",
       " 'live',\n",
       " '🏼',\n",
       " 'watch',\n",
       " 'thing',\n",
       " 'honor',\n",
       " 'night',\n",
       " 'do',\n",
       " '🇺',\n",
       " 'if',\n",
       " '—hillary',\n",
       " 'take',\n",
       " 'win',\n",
       " 'man',\n",
       " 'what',\n",
       " 'way',\n",
       " 'u.s.',\n",
       " '🇸',\n",
       " 'pay',\n",
       " 'to',\n",
       " 'world',\n",
       " 'in',\n",
       " '👁',\n",
       " 'life',\n",
       " 'campaign',\n",
       " 'believe',\n",
       " 'state',\n",
       " 'talk',\n",
       " 'think',\n",
       " 'tomorrow',\n",
       " 'join',\n",
       " 'democrats',\n",
       " 'purpose',\n",
       " 'house',\n",
       " 'clinton',\n",
       " 'happy',\n",
       " 'million',\n",
       " 'plan',\n",
       " 'hard',\n",
       " 'stand',\n",
       " 'ready',\n",
       " 'so',\n",
       " 'friend',\n",
       " 'united',\n",
       " '✨',\n",
       " 'high',\n",
       " 'strong',\n",
       " 'cut',\n",
       " 'just',\n",
       " 'mean',\n",
       " 'start',\n",
       " 'story',\n",
       " 'and',\n",
       " 'that',\n",
       " 'americans',\n",
       " 'week',\n",
       " 'support',\n",
       " '🏻',\n",
       " 'bad',\n",
       " 'when',\n",
       " 'give',\n",
       " 'now',\n",
       " 'national',\n",
       " '1',\n",
       " 'no',\n",
       " 'change',\n",
       " 'military',\n",
       " 'tell',\n",
       " 'lose',\n",
       " 'meeting',\n",
       " 'guy',\n",
       " 'proud',\n",
       " 'you',\n",
       " '$',\n",
       " 'long',\n",
       " 'show',\n",
       " 'hear',\n",
       " 'security',\n",
       " 'fight',\n",
       " 'run',\n",
       " 'on',\n",
       " 'deal',\n",
       " 'russia',\n",
       " 'sure',\n",
       " 'obama',\n",
       " 'states',\n",
       " 'leave',\n",
       " 'speak',\n",
       " 'white',\n",
       " 'business',\n",
       " 'korea',\n",
       " 'bill',\n",
       " 'border',\n",
       " 'north',\n",
       " 'call',\n",
       " 'care',\n",
       " 'sale',\n",
       " 'real',\n",
       " 'build',\n",
       " 'bring',\n",
       " 'lol',\n",
       " 'meet',\n",
       " 'kid',\n",
       " 'record',\n",
       " 'republicans',\n",
       " 'video',\n",
       " 'whatdoyoumean',\n",
       " 'ask',\n",
       " 'stop',\n",
       " '🔥',\n",
       " 'republican',\n",
       " 'soon',\n",
       " 'economy',\n",
       " 'find',\n",
       " 'history',\n",
       " 'ur',\n",
       " 'debate',\n",
       " 'lot',\n",
       " 'here',\n",
       " 'happen',\n",
       " 'forward',\n",
       " 'child',\n",
       " 'welcome',\n",
       " 'miss',\n",
       " 'for',\n",
       " 'album',\n",
       " 'all',\n",
       " 'try',\n",
       " 'place',\n",
       " 'company',\n",
       " 'healthcare',\n",
       " 'witness',\n",
       " 'song',\n",
       " 'wait',\n",
       " 'hope',\n",
       " '👏',\n",
       " 'wonderful',\n",
       " 'little',\n",
       " 'play',\n",
       " 'future',\n",
       " 'sign',\n",
       " 'feel',\n",
       " 'wall',\n",
       " 'candidate',\n",
       " 'girl',\n",
       " 'nation',\n",
       " 'china',\n",
       " 'trade',\n",
       " 'law',\n",
       " 'leader',\n",
       " 'medium',\n",
       " 'lie',\n",
       " 'with',\n",
       " '—@potu',\n",
       " 'turn',\n",
       " 'sorry',\n",
       " 'order',\n",
       " 'remember',\n",
       " 'word',\n",
       " 'matter',\n",
       " 'witnessthetour',\n",
       " '2',\n",
       " 'incredible',\n",
       " 'respect',\n",
       " 'policy',\n",
       " 'listen',\n",
       " 'tour',\n",
       " 'there',\n",
       " 'head',\n",
       " 'w/',\n",
       " 'obamacare',\n",
       " '🙏',\n",
       " '4',\n",
       " 'low',\n",
       " 't',\n",
       " 'yesterday',\n",
       " 'important',\n",
       " 'chance',\n",
       " 'senate',\n",
       " 'billion',\n",
       " 'free',\n",
       " 'college',\n",
       " 'fact',\n",
       " 'beautiful',\n",
       " 'congress',\n",
       " 'music',\n",
       " '🎶',\n",
       " 'act',\n",
       " 'administration',\n",
       " '3',\n",
       " 'fail',\n",
       " 'as',\n",
       " 'end',\n",
       " 'far',\n",
       " 'party',\n",
       " 'americanidol',\n",
       " 'lead',\n",
       " 'senator',\n",
       " 'include',\n",
       " 'dems',\n",
       " 'ticket',\n",
       " 'media',\n",
       " 'fbi',\n",
       " 'serve',\n",
       " 'check',\n",
       " 'save',\n",
       " 'dream',\n",
       " 'deserve',\n",
       " '🍒',\n",
       " 'break',\n",
       " 'home',\n",
       " '@whitehouse',\n",
       " 'massive',\n",
       " 'prayer',\n",
       " 'health',\n",
       " 'pence',\n",
       " 'yes',\n",
       " '💁',\n",
       " 'kind',\n",
       " 'can',\n",
       " 'reform',\n",
       " '8',\n",
       " 'heart',\n",
       " 'justice',\n",
       " 'w',\n",
       " 'safe',\n",
       " 'florida',\n",
       " 'general',\n",
       " 'pass',\n",
       " 'hit',\n",
       " 'continue',\n",
       " 'face',\n",
       " 'young',\n",
       " 'katy',\n",
       " 'morning',\n",
       " 'team',\n",
       " 'report',\n",
       " 'comey',\n",
       " 'special',\n",
       " 'close',\n",
       " 'send',\n",
       " 'spend',\n",
       " 'finally',\n",
       " '@skrillex',\n",
       " 'protect',\n",
       " 'release',\n",
       " 'totally',\n",
       " 'month',\n",
       " 'one',\n",
       " 'number',\n",
       " 'share',\n",
       " 'attack',\n",
       " 'market',\n",
       " 'middle',\n",
       " 'washington',\n",
       " 'true',\n",
       " 'first',\n",
       " 'amazing',\n",
       " 'money',\n",
       " 'stock',\n",
       " 'birthday',\n",
       " 'tune',\n",
       " '🙌',\n",
       " 'game',\n",
       " 'service',\n",
       " 'god',\n",
       " '10',\n",
       " '💅',\n",
       " 'stay',\n",
       " 'announce',\n",
       " 'decision',\n",
       " 'book',\n",
       " 'wrong',\n",
       " 'choice',\n",
       " 'chief',\n",
       " 'school',\n",
       " 'keep',\n",
       " 'city',\n",
       " 'economic',\n",
       " 'allow',\n",
       " 'daca',\n",
       " '➡',\n",
       " 'celebrate',\n",
       " 'person',\n",
       " 'o',\n",
       " 'prime',\n",
       " 'minister',\n",
       " 'dollar',\n",
       " '5',\n",
       " 'promise',\n",
       " 'refuse',\n",
       " 'hour',\n",
       " 'interview',\n",
       " 'nuclear',\n",
       " 'hold',\n",
       " 'crime',\n",
       " 'total',\n",
       " 'community',\n",
       " 'mexico',\n",
       " 'very',\n",
       " 'favorite',\n",
       " 'tough',\n",
       " 'p.m.',\n",
       " 'class',\n",
       " 'voice',\n",
       " 'worker',\n",
       " 'open',\n",
       " 'but',\n",
       " 'actually',\n",
       " 'again',\n",
       " 'presidential',\n",
       " 'track',\n",
       " '🎤',\n",
       " 'fire',\n",
       " '2017',\n",
       " 'use',\n",
       " 'office',\n",
       " 'nice',\n",
       " 'reason',\n",
       " 'ago',\n",
       " 'fun',\n",
       " 'grow',\n",
       " 'able',\n",
       " '🇦',\n",
       " 'immigration',\n",
       " 'march',\n",
       " 'why',\n",
       " 'read',\n",
       " 'student',\n",
       " 'elect',\n",
       " 'of',\n",
       " 'progress',\n",
       " 'stage',\n",
       " 'russian',\n",
       " 'poll',\n",
       " 'thought',\n",
       " 'secretary',\n",
       " 'rise',\n",
       " 'congrat',\n",
       " 'bro',\n",
       " 'power',\n",
       " 'major',\n",
       " 'post',\n",
       " 'message',\n",
       " 'fix',\n",
       " 'raise',\n",
       " 'last',\n",
       " 'ballot',\n",
       " 'it',\n",
       " 'tweet',\n",
       " 'illegal',\n",
       " 'collusion',\n",
       " 'forget',\n",
       " 'member',\n",
       " 'create',\n",
       " 'south',\n",
       " 'black',\n",
       " 'melania',\n",
       " 'democrat',\n",
       " 'mike',\n",
       " 'agree',\n",
       " 'easy',\n",
       " 'wish',\n",
       " 'base',\n",
       " 'set',\n",
       " 'debt',\n",
       " 'because',\n",
       " 'write',\n",
       " 'clear',\n",
       " 'question',\n",
       " 'small',\n",
       " 'maga',\n",
       " 'would',\n",
       " 'register',\n",
       " 'old',\n",
       " 'friday',\n",
       " 'at',\n",
       " 'debatenight',\n",
       " 'court',\n",
       " 'level',\n",
       " 'commander',\n",
       " 'room',\n",
       " '@foxandfriend',\n",
       " 'also',\n",
       " 'safety',\n",
       " 'terrible',\n",
       " 'together',\n",
       " 'november',\n",
       " 'hand',\n",
       " 'cuts',\n",
       " '7',\n",
       " '@nytime',\n",
       " 'action',\n",
       " 'weekend',\n",
       " 'hate',\n",
       " '💪',\n",
       " '—@flotu',\n",
       " 'away',\n",
       " 'problem',\n",
       " 'begin',\n",
       " 'government',\n",
       " 'crooked',\n",
       " 'point',\n",
       " 'step',\n",
       " 'line',\n",
       " 'repeal',\n",
       " 'veteran',\n",
       " 'race',\n",
       " 'catch',\n",
       " 'minute',\n",
       " 'drop',\n",
       " 'kill',\n",
       " 'pre',\n",
       " '🇷',\n",
       " 'learn',\n",
       " '@foxnew',\n",
       " 'host',\n",
       " 'brave',\n",
       " 'idea',\n",
       " 'gun',\n",
       " 'dem',\n",
       " 'powerful',\n",
       " 'single',\n",
       " 'purposetour',\n",
       " '😩',\n",
       " '🏼\\u200d',\n",
       " 'kpwww',\n",
       " 'john',\n",
       " 'witch',\n",
       " 'truly',\n",
       " 'rico',\n",
       " 'prove',\n",
       " 'press',\n",
       " 'your',\n",
       " 'endorse',\n",
       " 'moment',\n",
       " 'public',\n",
       " 'add',\n",
       " '→',\n",
       " 'hurt',\n",
       " 'war',\n",
       " 'treat',\n",
       " 'smart',\n",
       " 'replace',\n",
       " 'voter',\n",
       " 'foreign',\n",
       " 'rally',\n",
       " 'trust',\n",
       " 'follow',\n",
       " '@diplo',\n",
       " 'my',\n",
       " 'badly',\n",
       " 'system',\n",
       " 'value',\n",
       " 'puerto',\n",
       " 'governor',\n",
       " 'dangerous',\n",
       " 'push',\n",
       " 'never',\n",
       " 'speech',\n",
       " 'democracy',\n",
       " 'after',\n",
       " 'fair',\n",
       " 'cover',\n",
       " 'early',\n",
       " 'fan',\n",
       " 'more',\n",
       " 'baby',\n",
       " 'phone',\n",
       " '@potu',\n",
       " '🇨',\n",
       " 'climate',\n",
       " '💋',\n",
       " '👀',\n",
       " 'phony',\n",
       " 'jobs',\n",
       " 'weak',\n",
       " 'force',\n",
       " 'discuss',\n",
       " 'eye',\n",
       " 'every',\n",
       " 'may',\n",
       " 'crowd',\n",
       " 'back',\n",
       " 'alabama',\n",
       " 'rating',\n",
       " 'fall',\n",
       " 'isis',\n",
       " 'how',\n",
       " 'choose',\n",
       " '30',\n",
       " '9',\n",
       " 'terrorist',\n",
       " 'who',\n",
       " '🏈',\n",
       " 'preorderpurpose',\n",
       " '@katyperry',\n",
       " 'omg',\n",
       " 'return',\n",
       " 'federal',\n",
       " 'energy',\n",
       " 'york',\n",
       " 'r',\n",
       " '2018',\n",
       " 'defend',\n",
       " 'benefit',\n",
       " 'visit',\n",
       " '6',\n",
       " 'local',\n",
       " '2016',\n",
       " 'truth',\n",
       " 'dance',\n",
       " 'hurricane',\n",
       " '+',\n",
       " 'grateful',\n",
       " 'ok',\n",
       " 'wear',\n",
       " 'chip',\n",
       " 'statement',\n",
       " 'drug',\n",
       " '13',\n",
       " 'texas',\n",
       " 'despite',\n",
       " 'success',\n",
       " 'everyone',\n",
       " 'th',\n",
       " 'james',\n",
       " 'france',\n",
       " 'congratulation',\n",
       " 'inspire',\n",
       " 'die',\n",
       " '  ',\n",
       " 'death',\n",
       " 'large',\n",
       " 'hero',\n",
       " 'many',\n",
       " 'victim',\n",
       " 'confidence',\n",
       " 'deliver',\n",
       " 'tuesday',\n",
       " 'usa',\n",
       " 'understand',\n",
       " 'immigrant',\n",
       " 'trip',\n",
       " 'christmas',\n",
       " 'disrespect',\n",
       " 'insult',\n",
       " 'trail',\n",
       " 'pop',\n",
       " 'coldwater',\n",
       " 'fear',\n",
       " 'bear',\n",
       " '👊',\n",
       " '♀',\n",
       " 'bb',\n",
       " 's',\n",
       " 'group',\n",
       " 'disaster',\n",
       " 'cnn',\n",
       " 'human',\n",
       " 'japan',\n",
       " 'answer',\n",
       " 'control',\n",
       " 'we',\n",
       " 'move',\n",
       " 'nyc',\n",
       " 'brother',\n",
       " 'ban',\n",
       " '20',\n",
       " 'imagine',\n",
       " '—donald',\n",
       " 'chainedtotherhythm',\n",
       " 'victory',\n",
       " 'out',\n",
       " 'unemployment',\n",
       " 'case',\n",
       " 'past',\n",
       " 'dinner',\n",
       " '@flotus',\n",
       " 'entire',\n",
       " 'fantastic',\n",
       " 'approval',\n",
       " 'issue',\n",
       " 'b',\n",
       " 'tremendous',\n",
       " 'political',\n",
       " 'rest',\n",
       " 'monday',\n",
       " 'gold',\n",
       " 'police',\n",
       " 'opportunity',\n",
       " 'player',\n",
       " 'late',\n",
       " 'water',\n",
       " 'lift',\n",
       " '😂',\n",
       " 'excited',\n",
       " 'hunt',\n",
       " 'relationship',\n",
       " 'rate',\n",
       " 'investigation',\n",
       " 'travel',\n",
       " 'focus',\n",
       " 'luther',\n",
       " 'some',\n",
       " 'experience',\n",
       " 'reach',\n",
       " 'nfl',\n",
       " '17',\n",
       " '11',\n",
       " 'photo',\n",
       " 'europe',\n",
       " 'sit',\n",
       " 'parent',\n",
       " '🇧',\n",
       " '🎟',\n",
       " 'virginia',\n",
       " 'ohio',\n",
       " 'everybody',\n",
       " 'congratulations',\n",
       " 'rule',\n",
       " 'canada',\n",
       " 'address',\n",
       " 'lady',\n",
       " 'challenge',\n",
       " 'citizen',\n",
       " 'putin',\n",
       " 'judge',\n",
       " 'star',\n",
       " 'career',\n",
       " 'behalf',\n",
       " 'view',\n",
       " 'uk',\n",
       " 'presidency',\n",
       " 'london',\n",
       " 'v',\n",
       " 'picture',\n",
       " '📸',\n",
       " 'official',\n",
       " 'me',\n",
       " 'art',\n",
       " 'voting',\n",
       " 'available',\n",
       " '@theellenshow',\n",
       " 'mom',\n",
       " '@scooterbraun',\n",
       " 'hey',\n",
       " 'wanna',\n",
       " '@timkaine',\n",
       " 'iran',\n",
       " 'xi',\n",
       " 'west',\n",
       " 'light',\n",
       " 'peace',\n",
       " 'freedom',\n",
       " 'dead',\n",
       " 'street',\n",
       " 'afternoon',\n",
       " 'possible',\n",
       " 'our',\n",
       " 'land',\n",
       " 'violence',\n",
       " 'steel',\n",
       " 'increase',\n",
       " 'anthem',\n",
       " 'count',\n",
       " 'mind',\n",
       " 'teacher',\n",
       " 'son',\n",
       " 'are',\n",
       " 'program',\n",
       " 'enjoy',\n",
       " 'text',\n",
       " 'regulation',\n",
       " 'holiday',\n",
       " 'code',\n",
       " 'strange',\n",
       " 'mother',\n",
       " 'prepare',\n",
       " 'tear',\n",
       " 'wake',\n",
       " 'buddy',\n",
       " 'merch',\n",
       " '@edsheeran',\n",
       " 'sing',\n",
       " 'dress',\n",
       " 'vma',\n",
       " '🍕',\n",
       " 'stake',\n",
       " 'afford',\n",
       " '@realdonaldtrump',\n",
       " '💘',\n",
       " '😔',\n",
       " '⚡',\n",
       " 'thisishowwedo',\n",
       " 'luck',\n",
       " 'committee',\n",
       " 'm',\n",
       " 'leak',\n",
       " 'secret',\n",
       " 'launch',\n",
       " 'historic',\n",
       " 'cool',\n",
       " 'complete',\n",
       " 'maybe',\n",
       " 'dishonest',\n",
       " 'fine',\n",
       " 'un',\n",
       " 'wh',\n",
       " '50',\n",
       " 'offer',\n",
       " 'anti',\n",
       " 'put',\n",
       " 'an',\n",
       " 'these',\n",
       " 'tie',\n",
       " 'supporter',\n",
       " 'wage',\n",
       " 'women',\n",
       " 'where',\n",
       " 'decade',\n",
       " 'dnc',\n",
       " 'schumer',\n",
       " 'remark',\n",
       " 'only',\n",
       " 'even',\n",
       " '15',\n",
       " 'access',\n",
       " 'kick',\n",
       " 'over',\n",
       " 'finish',\n",
       " 'sleep',\n",
       " '12',\n",
       " 'oh',\n",
       " 'clean',\n",
       " 'sunday',\n",
       " '1st',\n",
       " 'color',\n",
       " '@kpcollection',\n",
       " 'till',\n",
       " '🙍',\n",
       " 'theprismaticworldtour',\n",
       " 'germany',\n",
       " 'charge',\n",
       " 'director',\n",
       " 'mark',\n",
       " 'executive',\n",
       " 'crazy',\n",
       " 'false',\n",
       " 'moon',\n",
       " 'n',\n",
       " 'approve',\n",
       " 'hat',\n",
       " 'test',\n",
       " 'california',\n",
       " 'deep',\n",
       " 'later',\n",
       " 'leadership',\n",
       " 'much',\n",
       " 'nomination',\n",
       " 'encourage',\n",
       " 'conference',\n",
       " 'air',\n",
       " 'from',\n",
       " 'effort',\n",
       " 'daughter',\n",
       " 'up',\n",
       " 'super',\n",
       " 'democratic',\n",
       " 'politic',\n",
       " 'social',\n",
       " 'season',\n",
       " 'strength',\n",
       " '🇵',\n",
       " 'buy',\n",
       " 'paris',\n",
       " 'insurance',\n",
       " 'equal',\n",
       " 'remix',\n",
       " 'ya',\n",
       " 'sister',\n",
       " 'dad',\n",
       " '@applemusic',\n",
       " 'yeah',\n",
       " 'purposealbum',\n",
       " '🎉',\n",
       " 'tuition',\n",
       " 'vision',\n",
       " 'tbt',\n",
       " '@covergirl',\n",
       " '🇳',\n",
       " 'source',\n",
       " 'concern',\n",
       " 'drive',\n",
       " 'al',\n",
       " 'enforcement',\n",
       " 'nbc',\n",
       " 'information',\n",
       " 'champion',\n",
       " 'name',\n",
       " 'too',\n",
       " '51',\n",
       " 'shoot',\n",
       " 'price',\n",
       " 'david',\n",
       " 'second',\n",
       " 'supreme',\n",
       " 'zero',\n",
       " 'wow',\n",
       " 'courage',\n",
       " 'better',\n",
       " 'flag',\n",
       " 'la',\n",
       " 'african',\n",
       " 'east',\n",
       " 'winner',\n",
       " 'date',\n",
       " 'vietnam',\n",
       " 'different',\n",
       " 'accept',\n",
       " 'chicago',\n",
       " 'khan',\n",
       " 'surprise',\n",
       " '@ryanseacr',\n",
       " 'bully',\n",
       " '47246',\n",
       " '@americanidol',\n",
       " 'cc',\n",
       " 'crisis',\n",
       " 'mr.',\n",
       " 'exist',\n",
       " 'arizona',\n",
       " 'sanctuary',\n",
       " 'chuck',\n",
       " 'fully',\n",
       " 'throw',\n",
       " 'abe',\n",
       " 'criminal',\n",
       " 'ball',\n",
       " 'c',\n",
       " 'department',\n",
       " 'shooting',\n",
       " 'trillion',\n",
       " 'pennsylvania',\n",
       " 'present',\n",
       " 'fast',\n",
       " 'reject',\n",
       " 'course',\n",
       " 'weapon',\n",
       " '60',\n",
       " 'result',\n",
       " 'bowl',\n",
       " 'worth',\n",
       " 'perfect',\n",
       " 'coverage',\n",
       " 'path',\n",
       " 'hi',\n",
       " 'da',\n",
       " 'spread',\n",
       " '100',\n",
       " 'bless',\n",
       " 'spirit',\n",
       " 'september',\n",
       " 'pick',\n",
       " 'sacrifice',\n",
       " 'glad',\n",
       " 'reality',\n",
       " 'lyric',\n",
       " 'premiere',\n",
       " '@lukebryanonline',\n",
       " '✌',\n",
       " '🐶',\n",
       " '🎄',\n",
       " 'fav',\n",
       " 'repost',\n",
       " 'represent',\n",
       " 'intelligence',\n",
       " 'gift',\n",
       " 'southern',\n",
       " 'letter',\n",
       " 'kim',\n",
       " 'well',\n",
       " 'evening',\n",
       " 'beat',\n",
       " 'seat',\n",
       " 'review',\n",
       " 'performance',\n",
       " 'arrive',\n",
       " 'council',\n",
       " 'gang',\n",
       " 'while',\n",
       " 'threat',\n",
       " 'king',\n",
       " 'boy',\n",
       " '@cnn',\n",
       " 'sick',\n",
       " 'form',\n",
       " 'confirm',\n",
       " 'roll',\n",
       " 'sad',\n",
       " '25',\n",
       " 'officer',\n",
       " 'center',\n",
       " 'australia',\n",
       " 'oval',\n",
       " 'mental',\n",
       " 'e',\n",
       " 'gain',\n",
       " 'investment',\n",
       " 'leg',\n",
       " 'lifetime',\n",
       " 'instead',\n",
       " 'conversation',\n",
       " '@vp',\n",
       " 'worry',\n",
       " 'u.',\n",
       " 'cuba',\n",
       " 'education',\n",
       " 'smile',\n",
       " 'stream',\n",
       " 'congrats',\n",
       " 'exclusive',\n",
       " 'purposethemovement',\n",
       " 'unfit',\n",
       " 'equality',\n",
       " 'episode',\n",
       " '🤷',\n",
       " '😍',\n",
       " '💃',\n",
       " 'x',\n",
       " '🎅',\n",
       " '🎃',\n",
       " '@hillaryclinton',\n",
       " '˚',\n",
       " 'primary',\n",
       " 'demand',\n",
       " 'receive',\n",
       " 'michigan',\n",
       " 'd.c.',\n",
       " 'pour']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n",
      "Processing row 3500\n",
      "Processing row 4000\n",
      "Processing row 4500\n",
      "Processing row 5000\n",
      "Processing row 5500\n",
      "Processing row 6000\n",
      "Processing row 6500\n",
      "Processing row 7000\n",
      "Processing row 7500\n",
      "Processing row 8000\n",
      "Processing row 8500\n",
      "Processing row 9000\n",
      "Processing row 9500\n",
      "Processing row 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-PRON-</th>\n",
       "      <th>be</th>\n",
       "      <th>trump</th>\n",
       "      <th>not</th>\n",
       "      <th>great</th>\n",
       "      <th>amp</th>\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>thank</th>\n",
       "      <th>'s</th>\n",
       "      <th>...</th>\n",
       "      <th>@hillaryclinton</th>\n",
       "      <th>˚</th>\n",
       "      <th>primary</th>\n",
       "      <th>demand</th>\n",
       "      <th>receive</th>\n",
       "      <th>michigan</th>\n",
       "      <th>d.c.</th>\n",
       "      <th>pour</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Statement, on, the, Iran, Nuclear, Deal, :)</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(John, Kerry, ca, n’t, get, over, the, fact, t...</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, will, be, speaking, to, my, friend, ,, Pre...</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Gina, Haspel, ,, my, highly, respected, nomin...</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, will, be, announcing, my, decision, on, th...</td>\n",
       "      <td>realDonaldTrump</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  -PRON- be trump not great amp \\n the thank 's       ...         \\\n",
       "0      0  0     0   0     0   0  0   0     0  0       ...          \n",
       "1      0  0     0   1     0   0  0   0     0  0       ...          \n",
       "2      1  0     0   0     0   0  0   1     0  0       ...          \n",
       "3      0  0     0   0     0   0  0   0     0  0       ...          \n",
       "4      1  0     0   0     0   0  0   0     0  0       ...          \n",
       "\n",
       "  @hillaryclinton  ˚ primary demand receive michigan d.c. pour  \\\n",
       "0               0  0       0      0       0        0    0    0   \n",
       "1               0  0       0      0       0        0    0    0   \n",
       "2               0  0       1      0       0        0    0    0   \n",
       "3               0  0       0      0       0        0    0    0   \n",
       "4               0  0       0      0       0        0    0    0   \n",
       "\n",
       "                                       text_sentence      text_source  \n",
       "0       (Statement, on, the, Iran, Nuclear, Deal, :)  realDonaldTrump  \n",
       "1  (John, Kerry, ca, n’t, get, over, the, fact, t...  realDonaldTrump  \n",
       "2  (I, will, be, speaking, to, my, friend, ,, Pre...  realDonaldTrump  \n",
       "3  (Gina, Haspel, ,, my, highly, respected, nomin...  realDonaldTrump  \n",
       "4  (I, will, be, announcing, my, decision, on, th...  realDonaldTrump  \n",
       "\n",
       "[5 rows x 1002 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(tweets, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10227 entries, 0 to 10226\n",
      "Columns: 1002 entries, -PRON- to text_source\n",
      "dtypes: object(1002)\n",
      "memory usage: 78.2+ MB\n"
     ]
    }
   ],
   "source": [
    "word_counts.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_counts.to_csv('tweet_word_counts.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models for BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0,\n",
    "                                                    stratify=Y\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "realDonaldTrump    1715\n",
       "katyperry          1708\n",
       "HillaryClinton     1514\n",
       "justinbieber       1199\n",
       "Name: text_source, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "realDonaldTrump    1143\n",
       "katyperry          1139\n",
       "HillaryClinton     1009\n",
       "justinbieber        800\n",
       "Name: text_source, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9488265971316818\n",
      "\n",
      "Test set score: 0.7311170862869714\n"
     ]
    }
   ],
   "source": [
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63067904, 0.73522228, 0.71847507, 0.73727984, 0.69358786])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(rfc, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rfc.fit(X_train, y_train).predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'HillaryClinton': 1488,\n",
       "         'justinbieber': 1067,\n",
       "         'katyperry': 1887,\n",
       "         'realDonaldTrump': 1694})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6136, 1000) (6136,)\n",
      "Training set score: 0.8864080834419817\n",
      "\n",
      "Test set score: 0.8127597164507455\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71812408, 0.81875916, 0.80938416, 0.82485323, 0.79001468])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.7865058670143416\n",
      "\n",
      "Test set score: 0.7450501099975556\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.61553493, 0.74059599, 0.7487781 , 0.78571429, 0.72589329])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Code adapted from http://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html\n",
    "# Set the parameters by cross-validation\n",
    "def gridsearch(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9],\n",
    "                     'C': [1, 10, 100, 1000, 10000]}]\n",
    "\n",
    "    scores = ['precision', 'recall']\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
    "                           scoring='%s_macro' % score)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To speed up production, we are going to take the X and Y test dataset, split it for testing and training\n",
    "#  and use grid search on that.  A smaller dataset will hopefully make this run faster.\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X_test, y_test, test_size=0.4,\n",
    "                                                    random_state=0, stratify=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "realDonaldTrump    0.279544\n",
       "katyperry          0.278321\n",
       "HillaryClinton     0.246536\n",
       "justinbieber       0.195599\n",
       "Name: text_source, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_train.value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.270 (+/-0.200) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.070 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.070 (+/-0.000) for {'C': 1, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.070 (+/-0.000) for {'C': 1, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.070 (+/-0.000) for {'C': 1, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.070 (+/-0.000) for {'C': 1, 'gamma': 1e-08, 'kernel': 'rbf'}\n",
      "0.070 (+/-0.000) for {'C': 1, 'gamma': 1e-09, 'kernel': 'rbf'}\n",
      "0.724 (+/-0.051) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.270 (+/-0.200) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.070 (+/-0.000) for {'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.070 (+/-0.000) for {'C': 10, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.070 (+/-0.000) for {'C': 10, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.070 (+/-0.000) for {'C': 10, 'gamma': 1e-08, 'kernel': 'rbf'}\n",
      "0.070 (+/-0.000) for {'C': 10, 'gamma': 1e-09, 'kernel': 'rbf'}\n",
      "0.748 (+/-0.027) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.724 (+/-0.055) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.270 (+/-0.200) for {'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.070 (+/-0.000) for {'C': 100, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.070 (+/-0.000) for {'C': 100, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.070 (+/-0.000) for {'C': 100, 'gamma': 1e-08, 'kernel': 'rbf'}\n",
      "0.070 (+/-0.000) for {'C': 100, 'gamma': 1e-09, 'kernel': 'rbf'}\n",
      "0.715 (+/-0.053) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.746 (+/-0.030) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.725 (+/-0.056) for {'C': 1000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.270 (+/-0.200) for {'C': 1000, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.070 (+/-0.000) for {'C': 1000, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.070 (+/-0.000) for {'C': 1000, 'gamma': 1e-08, 'kernel': 'rbf'}\n",
      "0.070 (+/-0.000) for {'C': 1000, 'gamma': 1e-09, 'kernel': 'rbf'}\n",
      "0.686 (+/-0.067) for {'C': 10000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.713 (+/-0.053) for {'C': 10000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.747 (+/-0.026) for {'C': 10000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.723 (+/-0.061) for {'C': 10000, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.270 (+/-0.200) for {'C': 10000, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.070 (+/-0.000) for {'C': 10000, 'gamma': 1e-08, 'kernel': 'rbf'}\n",
      "0.070 (+/-0.000) for {'C': 10000, 'gamma': 1e-09, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " HillaryClinton       0.82      0.77      0.80       404\n",
      "   justinbieber       0.70      0.62      0.66       320\n",
      "      katyperry       0.65      0.83      0.73       456\n",
      "realDonaldTrump       0.87      0.74      0.80       457\n",
      "\n",
      "    avg / total       0.76      0.75      0.75      1637\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.253 (+/-0.004) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.000) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.000) for {'C': 1, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.000) for {'C': 1, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.000) for {'C': 1, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.000) for {'C': 1, 'gamma': 1e-08, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.000) for {'C': 1, 'gamma': 1e-09, 'kernel': 'rbf'}\n",
      "0.596 (+/-0.045) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.254 (+/-0.006) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.000) for {'C': 10, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.000) for {'C': 10, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.000) for {'C': 10, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.000) for {'C': 10, 'gamma': 1e-08, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.000) for {'C': 10, 'gamma': 1e-09, 'kernel': 'rbf'}\n",
      "0.734 (+/-0.025) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.594 (+/-0.046) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.254 (+/-0.006) for {'C': 100, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.000) for {'C': 100, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.000) for {'C': 100, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.000) for {'C': 100, 'gamma': 1e-08, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.000) for {'C': 100, 'gamma': 1e-09, 'kernel': 'rbf'}\n",
      "0.720 (+/-0.054) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.731 (+/-0.030) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.595 (+/-0.047) for {'C': 1000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.254 (+/-0.006) for {'C': 1000, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.000) for {'C': 1000, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.000) for {'C': 1000, 'gamma': 1e-08, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.000) for {'C': 1000, 'gamma': 1e-09, 'kernel': 'rbf'}\n",
      "0.688 (+/-0.068) for {'C': 10000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.717 (+/-0.054) for {'C': 10000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.731 (+/-0.027) for {'C': 10000, 'gamma': 1e-05, 'kernel': 'rbf'}\n",
      "0.595 (+/-0.047) for {'C': 10000, 'gamma': 1e-06, 'kernel': 'rbf'}\n",
      "0.254 (+/-0.006) for {'C': 10000, 'gamma': 1e-07, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.000) for {'C': 10000, 'gamma': 1e-08, 'kernel': 'rbf'}\n",
      "0.250 (+/-0.000) for {'C': 10000, 'gamma': 1e-09, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " HillaryClinton       0.82      0.77      0.80       404\n",
      "   justinbieber       0.70      0.62      0.66       320\n",
      "      katyperry       0.65      0.83      0.73       456\n",
      "realDonaldTrump       0.87      0.74      0.80       457\n",
      "\n",
      "    avg / total       0.76      0.75      0.75      1637\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Show warning once\n",
    "import warnings\n",
    "warnings.filterwarnings('once')\n",
    "\n",
    "gridsearch(X2_train, y2_train, X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.8688070404172099\n",
      "\n",
      "Test set score: 0.781715961867514\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=100, gamma=0.001, kernel='rbf')\n",
    "\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Training set score:', svc.score(X_train, y_train))\n",
    "print('\\nTest set score:', svc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6790425 , 0.79970689, 0.79374389, 0.82387476, 0.77141459])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svc, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the different models built on BoW, it looks like logistic regression is least prone to overfitting and has the highest cross validation scores.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Analysis\n",
    "What if we don't have information on the handle that the tweet belongs to?  How could the tweets be categorized?  For this unsupervised learning problem, I will be using Latent Semantic Analysis to generate clusters of terms that reflects a topic.  First, I will use tf-idf, which converts the tweets into vectors.  Then I will apply dimension reduction (Singular Value Decomposition SVD) to reduce the feature space and generate the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 4116\n",
      "number of tweets: 6136\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(tweets['tweet'], test_size=0.4, random_state=0)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the tweets\n",
    "                             min_df=3, # only use words that appear at least three times\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case (since Donald Trump has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer tweets and shorter tweets get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "#Applying the vectorizer\n",
    "tweets_tfidf=vectorizer.fit_transform(tweets['tweet'])\n",
    "print(\"Number of features: %d\" % tweets_tfidf.get_shape()[1])\n",
    "\n",
    "#splitting into training and test sets\n",
    "X_train_tfidf, X_test_tfidf= train_test_split(tweets_tfidf, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "#Reshapes the vectorizer output into something people can read\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "\n",
    "#number of tweets\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "print('number of tweets: %d' %n)\n",
    "\n",
    "#A list of dictionaries, one per tweet\n",
    "tfidf_bytweet = [{} for _ in range(0,n)]\n",
    "\n",
    "#List of features\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "#for each tweet, lists the feature words and their tf-idf scores\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_bytweet[i][terms[j]] = X_train_tfidf_csr[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence: Make sure @realDonaldTrump's bullying never reaches the White House. Chip in now: \n",
      "Tf_idf vector: {'bullying': 0.4443024245049827, 'realdonaldtrump': 0.3651346305739997, 'chip': 0.3632204031774269, 'reaches': 0.465644263823698, 'sure': 0.3017629775755063, 'make': 0.23353437369164426, 'house': 0.2857506743178306, 'white': 0.30539444856515924}\n"
     ]
    }
   ],
   "source": [
    "#Keep in mind that the log base 2 of 1 is 0, so a tf-idf score of 0 indicates that the word was present once in that sentence.\n",
    "print('Original sentence:', X_train.iloc[3])\n",
    "print('Tf_idf vector:', tfidf_bytweet[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Let's apply SVD and see how the tweets are classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 33.40365749788838 \n",
      "\n",
      "Component 0:\n",
      "tweet\n",
      "@billboard :) thanks. Thank you #beliebers love you                                             0.723914\n",
      "And thanks for all the great musicians who inspire me everyday. Thank you. I love music         0.653585\n",
      "#PurposeTourGlendale another great show. Thank u                                                0.600435\n",
      "Thanks @PeoplesChoice                                                                           0.586154\n",
      "THANK YOU to all of the great volunteers helping out with #HurricaneHarvey relief in Texas!     0.585894\n",
      "thanks @mtvema :) \\n#EMABiggestFansJustinBieber                                                 0.585516\n",
      "Thanks Barry                                                                                    0.585280\n",
      "See more on my @OfficialFahlo #cosmo thanks                                                     0.585280\n",
      "@officialellenk thanks                                                                          0.585280\n",
      "@RyanCrossmusic thanks                                                                          0.585280\n",
      "Name: 0, dtype: float64\n",
      "\n",
      "\n",
      "Component 1:\n",
      "tweet\n",
      "Thanks Barry                                    0.784283\n",
      "@MTVUK thanks                                   0.784283\n",
      "Thanks @TeenChoiceFOX                           0.784283\n",
      "Thanks                                          0.784283\n",
      "See more on my @OfficialFahlo #cosmo thanks     0.784283\n",
      "Thanks                                          0.784283\n",
      "@greenIight thanks but painful                  0.784283\n",
      "Thanks Tori                                     0.784283\n",
      "@HilaryDuff thanks                              0.784283\n",
      "@christinaperri thanks                          0.784283\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "\n",
      "Component 2:\n",
      "tweet\n",
      "Thank you      0.59853\n",
      "Thank you      0.59853\n",
      "Thank you      0.59853\n",
      "THANK YOU!     0.59853\n",
      "Thank you!     0.59853\n",
      "Thank you!     0.59853\n",
      "Thank u        0.59853\n",
      "Thank u        0.59853\n",
      "Thank you!     0.59853\n",
      "Thank you      0.59853\n",
      "Name: 2, dtype: float64\n",
      "\n",
      "\n",
      "Component 3:\n",
      "tweet\n",
      "This is great                               0.632766\n",
      "MAKE AMERICA GREAT AGAIN!                   0.626405\n",
      "MAKE AMERICA GREAT AGAIN!                   0.626405\n",
      "MAKE AMERICA GREAT AGAIN!                   0.626405\n",
      "@ThePlumLineGS MAKE AMERICA GREAT AGAIN!    0.626405\n",
      "MAKE AMERICA GREAT AGAIN!                   0.626405\n",
      "MAKE AMERICA GREAT AGAIN!                   0.626405\n",
      "MAKE AMERICA GREAT AGAIN!                   0.626405\n",
      "MAKE AMERICA GREAT AGAIN!                   0.626405\n",
      "MAKE AMERICA GREAT AGAIN!                   0.626405\n",
      "Name: 3, dtype: float64\n",
      "\n",
      "\n",
      "Component 4:\n",
      "tweet\n",
      "I love you                                     0.889926\n",
      "I love it too                                  0.889926\n",
      "Love u all                                     0.889926\n",
      "@katyshoodrat I love him/her                   0.889926\n",
      "@cholewheeler but I love symmetry 😩            0.889926\n",
      "@ConditionalBabe too much for me but I love    0.889926\n",
      "Love                                           0.889926\n",
      "Love u too                                     0.889926\n",
      "love this                                      0.889926\n",
      "@lesbiyonce *listens to I love Kanye once*     0.887117\n",
      "Name: 4, dtype: float64\n",
      "\n",
      "\n",
      "Component 5:\n",
      "tweet\n",
      "Get 2 deluxe tracks &amp; exclusive photos when you get #Purpose at @Walmart                                                                                0.504425\n",
      ".@Beyonce &amp;\\n@S_C_ &amp;\\nHillary &amp;\\nYou?\\n                                                                                                         0.452225\n",
      "Perf palettes: Pollock &amp; Kooning                                                                                                                        0.434285\n",
      "Zuck &amp; Chan for prez 2024! 🙌🏼 ❤️                                                                                                                        0.434285\n",
      "I'm yin &amp; yang 🔥❤️\\n📸ronysphotobooth                                                                                                                    0.434285\n",
      "✂️cash me outside howbow dah✂️ S/O @mrchrismcmillan and justinandersoncolor &amp; @mmillerrider for…                                                        0.430828\n",
      "Many reports of peaceful protests by Iranian citizens fed up with regime’s corruption &amp; its squandering of the nati…                                    0.419575\n",
      "Sisters &amp; Stella 👩‍👩‍👧 @ Greece                                                                                                                         0.418940\n",
      "@katystumblrr cuz I tried to do it the 1st time &amp; I didn't have any space so I deleted an app &amp; had to do it again &amp; then my fv song came on    0.417721\n",
      "👀 The Daily Telegraph &amp; Chris Knowles 👎🏼                                                                                                                0.415797\n",
      "Name: 5, dtype: float64\n",
      "\n",
      "\n",
      "Component 6:\n",
      "tweet\n",
      "Never lol              0.752119\n",
      "Lol                    0.752119\n",
      "Lol                    0.752119\n",
      "@Popjustice lol        0.752119\n",
      "@TimTheLord lol        0.752119\n",
      "Me too. Lol            0.752119\n",
      "What are those. Lol    0.752119\n",
      "Lol                    0.752119\n",
      "@kingsleyyy lol        0.752119\n",
      "Lol                    0.752119\n",
      "Name: 6, dtype: float64\n",
      "\n",
      "\n",
      "Component 7:\n",
      "tweet\n",
      "Get 2 deluxe tracks &amp; exclusive photos when you get #Purpose at @Walmart     0.576281\n",
      "#PURPOSE                                                                         0.574473\n",
      "#PURPOSE                                                                         0.574473\n",
      "#PURPOSE                                                                         0.574473\n",
      "#whererunow #PURPOSE                                                             0.574473\n",
      "#PURPOSE                                                                         0.574473\n",
      "#PURPOSE Tracklist now up                                                        0.574473\n",
      "Purpose                                                                          0.574473\n",
      "PURPOSE                                                                          0.574473\n",
      "#1hour #PURPOSE                                                                  0.574473\n",
      "Name: 7, dtype: float64\n",
      "\n",
      "\n",
      "Component 8:\n",
      "tweet\n",
      "#PURPOSE                      0.479483\n",
      "#whererunow #PURPOSE          0.479483\n",
      "#PURPOSE                      0.479483\n",
      "#PURPOSE Tracklist now up     0.479483\n",
      "#1hour #PURPOSE               0.479483\n",
      "#PURPOSE                      0.479483\n",
      "#PURPOSE                      0.479483\n",
      "PURPOSE                       0.479483\n",
      "Purpose                       0.479483\n",
      "#PURPOSE                      0.479483\n",
      "Name: 8, dtype: float64\n",
      "\n",
      "\n",
      "Component 9:\n",
      "tweet\n",
      "#americanidol                                        0.914879\n",
      "💋#BenjaminGlaze #AmericanIdol                        0.914879\n",
      "#AmericanIdol                                        0.914879\n",
      "🎶OOOWEEEEOOOOWEEEEOOOOWOWWOWWOW🎶 #americanidol       0.914879\n",
      "I’m such a punk 🤦🏼‍♂#americanidol                    0.914879\n",
      "#AmericanIdol ✨                                      0.914879\n",
      "❤️❤️❤️ @maddiezahm ❤️❤️❤️ #americanidol              0.914879\n",
      "#AmericanIdol                                        0.914879\n",
      "❗️FIND YOUR TRIBE❗️#americanidol                     0.911490\n",
      "🐣 Spring has SPRUNG! @LaylaSpring 🐣 #americanidol    0.910259\n",
      "Name: 9, dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#Our SVD data reducer.  We are going to reduce the feature space to 200.\n",
    "svd= TruncatedSVD(200)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_train_lsa = lsa.fit_transform(X_train_tfidf)\n",
    "\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100, '\\n')\n",
    "\n",
    "#Looking at what sorts of paragraphs our solution considers similar, for the first five identified topics\n",
    "paras_by_component=pd.DataFrame(X_train_lsa,index=X_train)\n",
    "for i in range(10):\n",
    "    print('Component {}:'.format(i))\n",
    "    print(paras_by_component.loc[:,i].sort_values(ascending=False)[0:10])\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Latent Semantic Analysis, we are able to capture about 33% of the variance for all the tweet components.  The first three clusters have to do with thanks.  The fourth cluster capture tweets with the word \"great.\"  Make America Great Again tweets compose a good potion of this cluster.  Fifth cluster is around \"love\".  Sixth cluster are tweets that contain amperstands (&). Seventh cluster are lols.  Eighth and ninth cluster has the word \"purpose\", which is the title of Justin Beiber's new album.   The final cluster is about American Idol, which currently stars Katy Perry. \n",
    "\n",
    "In summary, some of the clusters do focus more on one twitter handle over the others. The \"great\" cluster is Donald Trump MAGA oriented.  #Purpose is mostly Justin Beiber.  #AmericanIdol is Katy Perry.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec\n",
    "Word2vec is the most common unsupervised neural network approach for NLP.  It converts words to vectors using distributed representation, where each word is represented by many neurons, and each neuron represents multiple words.  word2vec is powerful because it assigns a vector of random values to each word W, then shifts the vectors for the words around W in the sentence.  Words that are close to W have vectors that are closer together, while words that are not near W have vectors that are also far away.  Word2vec is great for tweets because tweets can contain the same concepts written in many different ways (e.g. expressing thanks).\n",
    "\n",
    "We do need are larger corpus when using word2vec.  So first, let's generate more tweets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 984497357092827135\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 973616503151980543\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 962084589329002495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=64, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 54992), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...800 tweets downloaded so far\n",
      "getting tweets before 956228551983841284\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 948732513190465536\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 938204950361804799\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 928795784740401152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/tweepy/binder.py:222: ResourceWarning: unclosed <socket.socket fd=68, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 54996), raddr=('104.244.42.130', 443)>\n",
      "  self.api.last_response = resp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...1600 tweets downloaded so far\n",
      "getting tweets before 921132488625340415\n",
      "...1800 tweets downloaded so far\n",
      "getting tweets before 912786414751723519\n",
      "...2000 tweets downloaded so far\n",
      "getting tweets before 904453885787389951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=34, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 54990), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=67, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 54991), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=66, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 54993), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=64, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 54994), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=70, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 54995), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=69, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 54997), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=68, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 54998), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=73, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 54999), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...2200 tweets downloaded so far\n",
      "getting tweets before 880153610738311167\n",
      "...2400 tweets downloaded so far\n",
      "getting tweets before 864178069061357567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/tweepy/binder.py:222: ResourceWarning: unclosed <socket.socket fd=34, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55001), raddr=('104.244.42.130', 443)>\n",
      "  self.api.last_response = resp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...2600 tweets downloaded so far\n",
      "getting tweets before 854073711732727807\n",
      "...2800 tweets downloaded so far\n",
      "getting tweets before 841703160213200895\n",
      "...3000 tweets downloaded so far\n",
      "getting tweets before 830092662245986303\n",
      "...3200 tweets downloaded so far\n",
      "getting tweets before 820806326531932159\n",
      "...3226 tweets downloaded so far\n",
      "getting tweets before 819252834965164032\n",
      "...3226 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=68, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55006), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=69, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55007), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 782250219027128319\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 759058522453659652\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 732313014720860159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=69, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55010), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...800 tweets downloaded so far\n",
      "getting tweets before 710577503329341439\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 688385432032133119\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 675059752959926272\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 654315653671727103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=72, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55014), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...1600 tweets downloaded so far\n",
      "getting tweets before 631925544141979647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=74, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55000), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=67, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55002), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=66, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55003), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=34, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55004), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=64, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55005), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=70, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55008), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=68, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55009), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=71, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55011), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=69, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55012), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=75, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55013), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=73, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55015), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...1800 tweets downloaded so far\n",
      "getting tweets before 618147962242252800\n",
      "...2000 tweets downloaded so far\n",
      "getting tweets before 603942876301557759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=66, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55017), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...2200 tweets downloaded so far\n",
      "getting tweets before 585486104272445439\n",
      "...2399 tweets downloaded so far\n",
      "getting tweets before 566675009628688385\n",
      "...2599 tweets downloaded so far\n",
      "getting tweets before 551829212370575359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=64, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55020), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...2798 tweets downloaded so far\n",
      "getting tweets before 535872666763137023\n",
      "...2996 tweets downloaded so far\n",
      "getting tweets before 520603040382849023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/tweepy/binder.py:222: ResourceWarning: unclosed <socket.socket fd=64, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55022), raddr=('104.244.42.130', 443)>\n",
      "  self.api.last_response = resp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...3196 tweets downloaded so far\n",
      "getting tweets before 506514154594004991\n",
      "...3211 tweets downloaded so far\n",
      "getting tweets before 504647157526183936\n",
      "...3211 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:43: ResourceWarning: unclosed <socket.socket fd=64, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55024), raddr=('104.244.42.130', 443)>\n",
      "/anaconda3/lib/python3.6/site-packages/tweepy/binder.py:222: ResourceWarning: unclosed <socket.socket fd=71, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55025), raddr=('104.244.42.130', 443)>\n",
      "  self.api.last_response = resp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 878366661224550399\n",
      "...399 tweets downloaded so far\n",
      "getting tweets before 695322347180457983\n",
      "...595 tweets downloaded so far\n",
      "getting tweets before 562468011416637440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=64, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55028), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...794 tweets downloaded so far\n",
      "getting tweets before 529690459270967295\n",
      "...994 tweets downloaded so far\n",
      "getting tweets before 488571123031085056\n",
      "...1191 tweets downloaded so far\n",
      "getting tweets before 478575175508557824\n",
      "...1389 tweets downloaded so far\n",
      "getting tweets before 434840507559067647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=74, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55032), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=72, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55016), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=34, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55018), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=67, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55019), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=66, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55021), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=68, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55023), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=70, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55026), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=71, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55027), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=69, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55029), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=64, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55030), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=73, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55031), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...1583 tweets downloaded so far\n",
      "getting tweets before 392910613380607999\n",
      "...1780 tweets downloaded so far\n",
      "getting tweets before 381165979772125183\n",
      "...1978 tweets downloaded so far\n",
      "getting tweets before 365543437325451263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=64, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55035), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...2175 tweets downloaded so far\n",
      "getting tweets before 349150331931852799\n",
      "...2370 tweets downloaded so far\n",
      "getting tweets before 333817717910011903\n",
      "...2569 tweets downloaded so far\n",
      "getting tweets before 315879839481610240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=67, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55038), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...2760 tweets downloaded so far\n",
      "getting tweets before 297758860435935233\n",
      "...2959 tweets downloaded so far\n",
      "getting tweets before 283132850021203967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=67, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55040), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...3153 tweets downloaded so far\n",
      "getting tweets before 270459671675015167\n",
      "...3190 tweets downloaded so far\n",
      "getting tweets before 268363645673680895\n",
      "...3190 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:43: ResourceWarning: unclosed <socket.socket fd=67, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55042), raddr=('104.244.42.130', 443)>\n",
      "/anaconda3/lib/python3.6/site-packages/tweepy/binder.py:222: ResourceWarning: unclosed <socket.socket fd=70, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55043), raddr=('104.244.42.130', 443)>\n",
      "  self.api.last_response = resp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting tweets before 953395261371494399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=72, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55044), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...400 tweets downloaded so far\n",
      "getting tweets before 930092897894092800\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 918085781322977279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=67, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55046), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...800 tweets downloaded so far\n",
      "getting tweets before 908027343293296639\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 896015893137956863\n",
      "...1200 tweets downloaded so far\n",
      "getting tweets before 885120099706970112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=67, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55049), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...1400 tweets downloaded so far\n",
      "getting tweets before 870361148738211839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/tweepy/models.py:140: ResourceWarning: unclosed <socket.socket fd=75, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55033), raddr=('104.244.42.130', 443)>\n",
      "  for k, v in json.items():\n",
      "/anaconda3/lib/python3.6/site-packages/tweepy/models.py:140: ResourceWarning: unclosed <socket.socket fd=34, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55034), raddr=('104.244.42.130', 443)>\n",
      "  for k, v in json.items():\n",
      "/anaconda3/lib/python3.6/site-packages/tweepy/models.py:140: ResourceWarning: unclosed <socket.socket fd=66, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55036), raddr=('104.244.42.130', 443)>\n",
      "  for k, v in json.items():\n",
      "/anaconda3/lib/python3.6/site-packages/tweepy/models.py:140: ResourceWarning: unclosed <socket.socket fd=64, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55037), raddr=('104.244.42.130', 443)>\n",
      "  for k, v in json.items():\n",
      "/anaconda3/lib/python3.6/site-packages/tweepy/models.py:140: ResourceWarning: unclosed <socket.socket fd=68, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55039), raddr=('104.244.42.130', 443)>\n",
      "  for k, v in json.items():\n",
      "/anaconda3/lib/python3.6/site-packages/tweepy/models.py:140: ResourceWarning: unclosed <socket.socket fd=69, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55041), raddr=('104.244.42.130', 443)>\n",
      "  for k, v in json.items():\n",
      "/anaconda3/lib/python3.6/site-packages/tweepy/models.py:140: ResourceWarning: unclosed <socket.socket fd=71, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55045), raddr=('104.244.42.130', 443)>\n",
      "  for k, v in json.items():\n",
      "/anaconda3/lib/python3.6/site-packages/tweepy/models.py:140: ResourceWarning: unclosed <socket.socket fd=70, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55047), raddr=('104.244.42.130', 443)>\n",
      "  for k, v in json.items():\n",
      "/anaconda3/lib/python3.6/site-packages/tweepy/models.py:140: ResourceWarning: unclosed <socket.socket fd=73, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55048), raddr=('104.244.42.130', 443)>\n",
      "  for k, v in json.items():\n",
      "/anaconda3/lib/python3.6/site-packages/tweepy/models.py:140: ResourceWarning: unclosed <socket.socket fd=72, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55050), raddr=('104.244.42.130', 443)>\n",
      "  for k, v in json.items():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...1600 tweets downloaded so far\n",
      "getting tweets before 854796024367517701\n",
      "...1800 tweets downloaded so far\n",
      "getting tweets before 844318544380788736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=66, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55053), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...2000 tweets downloaded so far\n",
      "getting tweets before 827569427910684673\n",
      "...2200 tweets downloaded so far\n",
      "getting tweets before 808416594271543303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=64, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55055), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...2400 tweets downloaded so far\n",
      "getting tweets before 785861325759062015\n",
      "...2600 tweets downloaded so far\n",
      "getting tweets before 770028695629209599\n",
      "...2800 tweets downloaded so far\n",
      "getting tweets before 753965400237506560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=68, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55058), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...3000 tweets downloaded so far\n",
      "getting tweets before 740910420299517951\n",
      "...3200 tweets downloaded so far\n",
      "getting tweets before 727601063189225473\n",
      "...3212 tweets downloaded so far\n",
      "getting tweets before 726147260879364095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/tweepy/binder.py:222: ResourceWarning: unclosed <socket.socket fd=70, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55061), raddr=('104.244.42.130', 443)>\n",
      "  self.api.last_response = resp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...3212 tweets downloaded so far\n",
      "getting tweets before 930050117737914367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=71, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55062), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n",
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=73, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55063), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...400 tweets downloaded so far\n",
      "getting tweets before 854295948985475071\n",
      "...600 tweets downloaded so far\n",
      "getting tweets before 782905543472013311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/json/decoder.py:355: ResourceWarning: unclosed <socket.socket fd=71, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55065), raddr=('104.244.42.130', 443)>\n",
      "  obj, end = self.scan_once(s, idx)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...800 tweets downloaded so far\n",
      "getting tweets before 716188469559566337\n",
      "...1000 tweets downloaded so far\n",
      "getting tweets before 611478471131316224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/tweepy/models.py:140: ResourceWarning: unclosed <socket.socket fd=71, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55067), raddr=('104.244.42.130', 443)>\n",
      "  for k, v in json.items():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...1200 tweets downloaded so far\n",
      "getting tweets before 487174462928736256\n",
      "...1400 tweets downloaded so far\n",
      "getting tweets before 384965928229695488\n",
      "...1564 tweets downloaded so far\n",
      "getting tweets before 313247631054864383\n",
      "...1564 tweets downloaded so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:43: ResourceWarning: unclosed <socket.socket fd=71, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55069), raddr=('104.244.42.130', 443)>\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:43: ResourceWarning: unclosed <socket.socket fd=76, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.29.239', 55070), raddr=('104.244.42.130', 443)>\n"
     ]
    }
   ],
   "source": [
    "# Getting more tweets from Ellen Degeneres, Barack Obama, Rihanna, Senator John Mccain, and Pope Francis\n",
    "more_twts = get_all_tweets(['TheEllenShow','BarackObama','Rihanna','senjohnmccain','pontifex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TheEllenShow     3226\n",
       "SenJohnMcCain    3212\n",
       "BarackObama      3211\n",
       "rihanna          3190\n",
       "Pontifex         1564\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_twts[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_twts.columns = ['screenname','tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_twts['tweet'] = more_twts['tweet'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(len(tweets['tweet'])):\n",
    "    more_twts['tweet'][r] = text_cleaner(more_twts['tweet'][r])\n",
    "\n",
    "#Dropping retweets    \n",
    "more_twts = more_twts[more_twts['tweet'].str.contains(\"RT\") == False].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/msgpack_numpy.py:84: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  dtype=np.dtype(descr)).reshape(obj[b'shape'])\n"
     ]
    }
   ],
   "source": [
    "# Parse tweets\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "parsed = []\n",
    "\n",
    "for r in more_twts['tweet']:\n",
    "    p = nlp(r)\n",
    "    parsed.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_twts['parsed'] = parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding tweets from previous pull to dataframe.\n",
    "df = pd.concat([more_twts, tweets], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screenname</th>\n",
       "      <th>tweet</th>\n",
       "      <th>parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23504</th>\n",
       "      <td>katyperry</td>\n",
       "      <td>Um...YES IT IS #magritte</td>\n",
       "      <td>(Um, ..., YES, IT, IS, #, magritte)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23505</th>\n",
       "      <td>katyperry</td>\n",
       "      <td>This could be us but ur playin' #magritte</td>\n",
       "      <td>(This, could, be, us, but, ur, playin, ', #, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23506</th>\n",
       "      <td>katyperry</td>\n",
       "      <td>First things first, I'm surrealist. #magritte</td>\n",
       "      <td>(First, things, first, ,, I, 'm, surrealist, ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23507</th>\n",
       "      <td>katyperry</td>\n",
       "      <td>GO SEE THE MAGRITTE EXHIBIT artinstitutechi It...</td>\n",
       "      <td>(GO, SEE, THE, MAGRITTE, EXHIBIT, artinstitute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23508</th>\n",
       "      <td>katyperry</td>\n",
       "      <td>Dear Jason @Starbucks on Ohio &amp;amp; N State in...</td>\n",
       "      <td>(Dear, Jason, @Starbucks, on, Ohio, &amp;, amp, ;,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      screenname                                              tweet  \\\n",
       "23504  katyperry                          Um...YES IT IS #magritte    \n",
       "23505  katyperry         This could be us but ur playin' #magritte    \n",
       "23506  katyperry     First things first, I'm surrealist. #magritte    \n",
       "23507  katyperry  GO SEE THE MAGRITTE EXHIBIT artinstitutechi It...   \n",
       "23508  katyperry  Dear Jason @Starbucks on Ohio &amp; N State in...   \n",
       "\n",
       "                                                  parsed  \n",
       "23504                (Um, ..., YES, IT, IS, #, magritte)  \n",
       "23505  (This, could, be, us, but, ur, playin, ', #, m...  \n",
       "23506  (First, things, first, ,, I, 'm, surrealist, ....  \n",
       "23507  (GO, SEE, THE, MAGRITTE, EXHIBIT, artinstitute...  \n",
       "23508  (Dear, Jason, @Starbucks, on, Ohio, &, amp, ;,...  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['splittinguptogether', 'start', '5', 'minute', 'be', 'east', 'coast', 'west', 'coast', 'consider', 'warning']\n",
      "We have 23509 tweets and 168978 tokens.\n"
     ]
    }
   ],
   "source": [
    "# Organize the parsed doc into sentences, while filtering out punctuation\n",
    "# and stop words, and converting words to lower case lemmas.\n",
    "twts = []\n",
    "for tweet in df['parsed']:\n",
    "    tweet = [\n",
    "        token.lemma_.lower()\n",
    "        for token in tweet\n",
    "        if not token.is_stop\n",
    "        and not token.is_punct\n",
    "    ]\n",
    "    twts.append(tweet)\n",
    "\n",
    "\n",
    "print(twts[10])\n",
    "print('We have {} tweets and {} tokens.'.format(len(twts), len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "\n",
    "model = word2vec.Word2Vec(\n",
    "    twts,\n",
    "    workers=4,     # Number of threads to run in parallel (if your computer does parallel processing).\n",
    "    min_count=10,  # Minimum word count threshold.\n",
    "    window=6,      # Number of words around target word to consider.\n",
    "    sg=0,          # Use CBOW because our corpus is small.\n",
    "    sample=1e-3 ,  # Penalize frequent words.\n",
    "    size=300,      # Word vector length.\n",
    "    hs=1           # Use hierarchical softmax.\n",
    ")\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['happy', 'birthday', '-pron-', 'be', 'excited', 'come', 'let', 'know', 'need', 'direction', 'street', 'name', 'jennifer', 'not', 'word', 'but', 'song', '\\n\\n', 'watch', 'clip', 'wait', 'minute', 'steal', 'plane', 'just', 'this', 'good', 'well', '’', 'thankssponsor', 'if', 'guess', 'mystery', 'audience', 'win', 'huge', 'introduce', 'way', 'tell', 'little', 'family', 'west', 'coast', 'time', 'splittinguptogether', 'start', '5', 'east', 'consider', 'warning', 'think', 'stand', 'chance', 'buy', 'friend', 'day', 'how', 'thing', 'give', 'cool', 'performance', 'note', 'self', 'read', '’s', 'book', 'sure', 'new', 'movie', 'for', 'appreciate', 'teacher', 'launch', 'may', '7', '2018', 'leave', '\\n', 'right', 'tomorrow', 'go', 'to', 'hit', 'high', 'sometimes', 'exactly', 'plan', 'play', 'want', 'enter', '❤', '️', 'somebody', 'bring', 'big', 'idea', 'rose', 'feel', 'sister', 'celebrate', 'joke', 'what', 'album', 'hope', 'call', 'do', 'quick', 'prayer', 'video', '@andylassner', 'get', 'have', 'gif', 'someone', 'home', 'sign', 'the', 'cast', 'drinking', 'game', 'update', 'baby', '@melissamccarthy', 'ask', '@kanyew', 'find', 'ellen', 'and', '20', 'shop', 'send', 'road', 'app', 'happen', 'amber', 'kind', 'person', 'especially', 'wonderful', 'h', 'perform', 'bad', 'news', 'keep', 'dance', 'dare', 'last', 'when', 'commercial', 'stop', ' ', 'david', 'head', 'crew', '@jlo', 'tough', 'there', 'surprise', 'love', 'stuff', 'p', '@therock', 'rock', 'house', 'hero', 'james', 'meet', 'shooter', 'week', 'finally', 'party', 'talk', 'turn', '@jtimberlake', 'long', 'round', 'never', 'ever', 'no', 'nobody', 'look', 'beautiful', 'example', 'kid', 'hard', 'secret', 'justin', 'lot', 'fun', 'literally', 'control', 'people', 'twitter', 'congratulation', 'star', 'walk', 'all', 'trouble', 'night', 'kim', 'kanye', '@kimkardashian', 'will', 'believe', 'tweet', 'hold', 'on', 'reason', 'amazing', 'littlebigshot', 'tonight', 'here', 'confirm', 'smell', 'sing', 'continue', 'internet', 'break', 'world', 'tour', 'understand', 'cut', 'sunday', 'episode', \"'s\", 'change', 'monday', 'got', 'summer', 'second', 'season', 'gameofgames', 'a', 'tribute', 'incredible', 'body', 'work', 'post', 'zero', '@channingtatum', 'wonder', 'like', 'please', 'enjoy', 'kelly', 's', 'important', 'role', 'chip', 'life', 'knock', 'tuesday', 'young', 'red', 'carpet', 'power', 'glad', 'today', 'december', '5th', 'sweat', 'lady', 'gentleman', 'president', 'run', 'remember', 'see', 'thursday', 'man', 'welcome', 'anytime', 'live', 'brilliant', 'child', 'free', 'available', 'these', 'sit', 'crazy', 'rich', 'boy', 'kate', 'line', 'trailer', 'ready', 'blow', 'away', 'tiny', 'genius', 'remind', 'show', 'proud', '@eminem', 'old', 'school', 'favorite', 'thank', 'billy', '@jimmykimmel', 'clean', 'shout', 'excuse', 'accomplish', 'then', 'charge', '15', 'hour', 'earth', 'definitely', '9', 'planet', 'option', 'oh', 'in', 'honor', 'present', 'defend', 'store', 'raise', 'thebachelor', 'beat', 'rule', 'year', 'woman', 'who', 'hey', 'mine', 'brother', 'better', 'nice', 'announce', '50', 'cat', 'cover', 'issue', 'st', 'real', 'barbara', 'bush', 'great', 'magic', 'average', 'try', 'outside', 'las', 'vegas', 'maybe', '@nickiminaj', 'hilarious', 'forget', 'say', 'lord', 'talent', 'gift', 'card', 'that', 'yep', 'direct', 'black', 'promise', 'phone', 'double', 'edbypetsmart', 'vote', '@ellentube', '@headsup', 'easy', 'miss', 'abc', 'lie', '@chancetherapper', 'rain', 'american', 'til', 'girl', '10', 'would', 'attend', 'sorry', 'perfect', 'weekend', 'suffer', 'leg', 'white', 'special', 'fill', 'joy', 'set', 'iphone', '8', 'each', 'sell', 'save', 'lead', 'mad', 'about', '25', 'million', 'view', 'job', 'so', 'shirt', 'omg', 'write', 'interview', 'face', 'nominate', 'check', 'jack', 'husband', 'john', 'follow', 'instagram', 'hurry', 'choose', 'mean', 'marry', '@blakeshelton', 'water', '@pharrell', 'shoe', 'wear', 'age', 'forward', 'equal', 'pay', '100', 'ago', 'fair', 'funny', 'couple', 'lgbt', 'navy', 'drink', 'unbelievable', 'warn', 'heart', 'morning', 'entire', 'community', 'affect', 'eat', 'dedication', 'studio', 'e', '+', 'b', 'shoot', 'deal', 'stage', 'now', 'cheer', 'even', 'yeah', 'hat', 'tbt', '2', '@imkristenbell', '@daxshepard1', 'deserve', 'ride', 'help', 'light', 'speech', 'lose', 'message', 'unity', 'laugh', 'french', 'pro', 'positive', 'thought', '@youtube', 'hop', 'everyday', 'wish', 'propose', 'statement', 'marriage', 'answer', 'pretty', 'dog', 'political', 'office', 'share', 'difference', 'hear', 'wanna', 'easter', 'ear', 'april', 'hide', 'story', 'seriously', 'meeting', '@oprah', 'involve', '@ladygaga', 'tune', 'premiere', 'spring', 'everybody', 'm', 'where', 'hand', 'use', 'grab', 'winter', 'soon', 'tv', 'teach', 'jim', 'march', 'speak', 'inspiring', 'powerful', 'donate', 'san', 'grateful', 'goodness', 'friday', 'naked', 'put', 'concert', 'code', 'truth', 'photo', 'dream', 'true', '8/7c', '@nbc', 'support', 't', '@rwitherspoon', 'bold', 'opinion', 'clearly', 'close', 'room', 'first', 'out', 'handle', 'event', 'learn', 'ya', 'lesson', '@official_twitch', 'open', 'exclusive', 'peek', 'national', 'warm', 'tag', 'guest', 'christian', 'suit', 'yes', 'protect', 'canadian', 'gold', 'date', 'or', 'rest', 'shoulder', 'oscar', 'burn', 'absolutely', 'take', 'listen', 'shape', 'shot', 'adorable', '@adamlevine', '3', 'mind', 'montecito', 'top', 'o', 'lucky', 'moment', 'donation', 'feeling', 'professional', 'level', 'explain', 'oscars', 'nbc', 'everyone', 'every', 'drop', 'sweet', 'guy', 'strange', 'smile', 'challenge', 'end', 'lip', '@ddlovato', 'reveal', 'spot', 'nick', 'stay', 'tip', 'n', 'debut', 'music', 'far', 'trump', 'also', 'expert', 'review', 'bill', 'impression', 'prepare', 'actually', 'later', 'mrs.', 'selfie', 'bae', 'internationalwomensday', 'spread', 'impressive', 'credit', 'ban', 'equality', 'trip', 'anybody', 'fine', 'spin', '$', 'k', 'straight', 'holy', 'bachelor', 'recap', 'facebook', 'finale', 'coach', 'suppose', 'picture', 'host', 'award', 'bird', 'chris', 'martin', 'nothing', 'sound', 'moore', 'cry', '⚡', '@kerrywashington', 'mood', 'inspire', 'ice', 'mom', 'giveaway', 'notice', 'medal', 'follower', 'unforgettable', 'scar', 'wrong', 'winner', 'olympic', 'success', 'why', 'small', 'member', 'make', 'pitch', 'scare', 'mr.', 'can', 'release', 'target', 'repeat', 'animal', 'foundation', 'fund', 'yo', 'month', 'us', 'team', '1', 'fully', 'north', 'korean', '@drake', 'phoenix', 'luck', 'victory', '@michelleobama', 'america', 'catch', 'student', 'create', 'massive', 'joyful', 'green', 'hurt', 'celebrity', 'bff', 'point', 'hug', 'legend', '😉', 'mess', 'producer', 'wow', 'brielle', 'scientist', 'one', 'price', 'cold', 'momsplaining', 'digital', 'series', 'push', 'up', 'amp', '@rihanna', 'shin', 'bright', 'diamond', 'th', '6', 'olympics', 'havana', 'lyric', 'presidential', 'macey', 'download', 'deck', 'realize', 'single', '@edsheeran', 'awesome', '@theweeknd', 'lol', 'interested', 'place', 'final', 'sex', 'response', 'shooting', 'voice', 'food', 'critic', 'bit', 'include', 'action', 'law', 'epidemic', 'country', '@officialjld', 'advice', 'dr.', 'spend', 'portia', 'throw', 'philly', 'rat', 'honored', 'humble', '🙏', '🏼', 'simple', 'talented', 'cup', 'deliver', 'impossible', '@pink', 'two', 'noise', 'carry', 'public', 'comment', 'class', 'wrap', 'brand', 'most', 'tradition', 'superbowl', 'begin', '30', 'ft', 'living', 'aka', '@diddy', '🙌', '♀', '😂', 'record', 'executive', 'longer', 'able', 'film', 'apology', 'city', 'mother', 'company', 'death', 'tree', 'contestant', 'knoworgo', 'require', 'excellent', 'strategy', 'grammy', 'choice', 'partner', 'hang', 'paris', 'fall', 'rise', 'midnight', 'really', 'trap', 'door', 'puppy', 'philadelphia', 'safe', 'kill', 'always', 'worth', '@hillaryclinton', 'art', 'hundred', 'volunteer', 'santa', 'fantastic', 'actor', 'deeply', 'probably', 'reach', 'onemillionactsofgood', 'w', 'highlight', '  ', 'five', 'encounter', 'melania', 'backstage', 'retweet', 'bell', 'mental', 'health', 'initiative', 'wind', 'my', 'beach', 'sotu', 'de', 'wife', 'poor', 'base', 'text', 'bet', 'pick', 'pie', 'debate', 'plus', 'decide', 'visit', 'treat', 'staff', 'best', 'theme', 'mouth', 'fly', 'neighbor', 'emergency', 'train', 'actual', 'character', 'grace', '24', 'u.', 'such', 'pet', 'only', 'god', '@jkcorden', '🍷', 'grow', '🤔', '💁', '4', 'you', 'imagine', 'tax', 'allow', 'y', 'military', 'ed', 'too', 'sun', 'money', 'closer', 'test', 'capital', '3rd', 'united', 'states', 'since', 'u', 'case', 'chief', 'officer', 'daddy', 'possible', 'pull', 'result', 'some', 'jeff', 'box', 'd', '60', 'rate', 'montage', 'interesting', 'island', 'stream', 'alive', 'relationship', 'early', 'queen', 'fan', 'wall', 'survey', 'kindness', 'wisdom', 'daughter', 'college', 'government', 'monster', 'goal', 'dear', 'clear', 'ball', 'match', 'tie', 'drive', 'doctor', 'nose', 'fire', 'confidence', 'campaign', 'recognize', '@fallontonight', '@jimmyfallon', 'wide', 'football', 'field', 'dad', 'business', 'father', 'pass', 'hq', 'list', 'bomb', 'bar', 'emoji', 'resident', 'mexico', 'worry', 'eye', 'l', 'detail', 'chair', 'goldenglobes', 'river', 'rescue', 'worker', 'brave', 'smart', 'bed', 'still', 'mention', '4th', 'disaster', 'artist', 'finish', 'terrific', 'figure', 'hall', 'area', 'mike', 'player', 'wake', 'discover', 'conspiracy', 'battle', 'california', 'wildfire', 'congrat', 'joe', 'fast', 'certain', 'honestly', 'twin', 'hot', 'wh', 'zone', 'danger', 'another', 'seat', '@todayshow', 'co', 'resolution', 'thrill', 'sleep', 'purpose', '2017', 'christmas', 'makeup', 'merry', 'draw', '@ryanseacr', 'holiday', 'ellenshowmemore', 'bear', 'question', 'could', 'tom', 'agree', 'fact', 'kevin', '@mileycyrus', 'preview', 'after', 'traffic', 'terrible', 'p.m.', 'prime', 'afraid', 'firefighter', 'order', 'sexy', 'sue', 'at', 'prince', '@lukebryanonline', 'suspend', 'foot', 'air', 'add', 'summit', 'journey', 'alabama', 'ha', 'roy', 'attorney', 'matter', '12day', 'gay', 'safety', 'threat', 'pray', 'pic', '1st', 'yesterday', '12daysofgiveaways', '13', 'expect', 'deny', 'legal', 'county', 'apple', 'fragrance', 'commitment', 'son', '12', 'step', 'australia', 'lovewins', 'register', 'effect', 'memory', 'southern', 'impact', '11', '=', 'civil', 'election', 'loser', 'fight', 'competition', 'late', 'attention', 'repost', 'together', 'graduate', 'academy', 'inspiration', 'short', 'nomination', 'while', 'hair', 'sneak', 'bts', 'thanksgiving', 'gratitude', 'table', 'thankful', 'act', 'earn', 'employee', 'andy', 'ama', 'anniversary', 'pop', 'band', 'cute', '@joebiden', 'mate', 'snapchat', 'noah', 'petition', 'ticket', 'extra', 'puerto', 'rico', 'row', 'popular', 'history', 'car', 'compassion', 'social', 'intelligence', 'patience', 'quality', 'limit', 'space', 'group', 'idol', 'replace', 'billboard', 'gender', 'care', 'politic', 'w/', '😭', 'risk', 'reward', 'respect', 'veteran', 'build', 'receive', 'hotel', 'join', 'as', 'happiness', 'honest', 'lil', 'search', 'nashville', 'past', 'future', 'exciting', 'halloween', 'effort', 'arena', 'announcement', 'china', 'dress', 'texas', 'orlando', 'near', 'amazon', 'human', 'account', 'justice', 'prize', '@uhouston', 'serve', 'c', 'ny', 'trust', 'return', 'costume', 'legislation', 'george', 'number', ' \\n', 'half', 'americanidol', 'matt', 'crowd', 'houston', 'russian', 'ad', 'compare', '@katyperry', 'turnout', '2nd', 'kiss', 'color', 'nfl', 'everything', 'building', 'any', 'ryan', 'image', 'dangerous', 'arrive', 'sad', 'kat', 'billion', 'contribute', 'silence', 'scene', 'epic', 'damage', 'devastating', 'common', 'spirit', 'bout', 'sexual', 'assault', 'jesus', 'security', 'guard', 'wild', 'andrew', 'emmy', 'puertorico', 'model', 'damn', 'cake', 'afford', 'swear', 'playing', 'ten', 'dollar', 'responder', 'ford', 'mississippi', 'refuse', 'service', 'treatment', 'beauty', 'cancer', '@usher', '✔', 'hi', 'anti', 'totally', 'courageous', 'hurricane', 'victim', 'center', 'more', 'paper', 'succeed', 'reporter', 'thousand', 'count', 'privilege', 'grand', '23', 'kick', 'destroy', 'fellow', 'americans', 'style', 'protest', 'fit', 'strong', 'spell', 'angel', 'ellen15', 'feature', 'bob', 'conversation', 'exchange', '🇲', '🇽', 'root', 'language', 'path', 'till', '🔥', 'tape', 'piece', 'emmys', 'african', 'apologize', 'mama', 'which', 'sock', 'produce', 'x', 'september', 'youtube', 'should', 'three', 'preorder', 'parent', '51', 'coverage', 'florida', 'bro', 'hate', 'strength', 'prove', 'benefit', 'relief', 'camera', 'charlottesville', \"i'm\", 'an', 'labor', 'ridiculous', 'aid', 'boston', 'vma', 'back', 'chicago', 'virginia', 'inside', 'from', 'harvey', 'down', 'under', 'hurricaneharvey', 'belong', '14', 'invest', 'jerry', 'original', 'odd', 'hill', 'darkness', 'corner', 'virgin', 'bday', 'progress', 'cross', 'laughdancepartner', 'lover', 'saturday', 'tea', 'instead', 'retirement', '500', 'before', 'visa', '@arianagrande', 'opponent', 'something', 'move', 'friendship', 'achievement', 'wednesday', 'cruise', 'prescription', 'pride', 'material', 'officially', 'fail', 'michael', 'skill', 'complete', 'four', 'me', 'london', 'manchester', 'congratulations', 'jet', 'anyone', '90', 'pink', 'g', 'attitude', 'freedom', 'firstdates', 'much', 'bbma', 'accident', 'war', 'ok', 'bitch', '👩', '🎤', 'accord', 'spill', 'own', 'chart', 'stick', 'hire', 'stake', 'captain', 'hospital', 'deep', '2015', 'different', 'loveislove', 'putin', 'judge', 'gun', 'nearly', 'package', 'confession', 'apply', 'reality', 'noon', 'knowledge', 'education', 'tear', 'track', 'blue', 'total', 'doubt', 'willing', 'tim', 'yrs', 'state', 'online', 'with', 'middle', 'organization', '16', 'market', 'europe', 'career', 'heaven', 'mary', 'faith', 'global', 'official', 'r', 'rating', 'fix', 'forever', '420', 'roll', 'bank', 'hollywood', 'nugget', 'rihanna', 'touch', 'exist', 'sport', 'productive', 'invite', 'lipstick', 'ceiling', 'wig', 'nyc', 'dark', 'combat', 'saint', 'sailor', 'represent', 'club', 'native', '31', 'session', 'science', 'personal', 'rehearsal', 'pre', 'society', \"y'all\", 'shut', 'block', 'super', 'lay', 'opportunity', 'focus', 'offer', 'improve', 'york', 'outstanding', 'project', 'crash', 'full', 'court', 'fashion', 'develop', 'dead', 'healthy', 'jackson', 'la', 'land', 'accept', 'treasure', 'opening', '40', 'embrace', 'remove', 'muslim', 'attack', '😘', 'mar', 'champion', 'werk', '@bigsean', 'product', 'apart', 'loan', 'letter', 'valentine', 'low', 'cap', 'basketball', 'consecutive', 'trade', 'debt', 'course', 'mountain', 'subject', 'chemical', 'main', 'ass', 'georgia', 'tech', 'energy', 'pose', 'cuz', 'immediately', 'border', 'patrol', 'size', 'stadium', 'source', 'atl', 'est', 'bowl', 'arm', 'steel', 'atlanta', 'because', 'immigrant', 'current', 'of', 'decision', 'chinese', 'farmer', 'peace', '.@potus', '@flotu', 'address', '@potus', 'press', 'conference', 'jean', 'legendary', 'sin', 'dinner', 'south', 'page', 'drought', 'it', 'potential', 'nuclear', 'weapon', 'africa', 'passing', 'michelle', 'task', 'nation', 'achieve', 'singapore', 'advocate', 'dan', 'movement', 'graham', 'servant', 'king', '26', 'bus', 'rally', 'engage', 'al', 'mission', 'v', 'reflect', 'ahead', 'behalf', 'obama', 'folk', 'congratulate', 'determine', 'grant', 'concrete', 'reduce', 'violence', 'midst', 'harm', 'hatred', 'survivor', 'hello', 'thrilled', 'leader', 'rebuild', 'lifetime', 'endure', 'tragedy', 'usa', 'expand', 'soldier', 'citizen', 'legacy', 'mexican', 'un', 'ideal', 'terror', 'religion', 'mccain', 'fighter', 'awareness', 'sacrifice', 'discuss', 'condolence', 'through', 'resolve', 'wound', 'uk', 'ally', 'chuck', 'international', 'women', 'almost', '28', 'part', 'hearing', 'pm', 'et', 'weekly', 'obamacare', 'economy', 'force', 'actonclimate', 'october', 'wage', 'percent', 'getcovered', 'marketplace', 'organizing', 'condition', 'fear', 'uninsured', 'affordable', 'insurance', 'enrollment', 'senate', 'obstruction', 'supreme', 'process', 'unacceptable', 'depend', 'november', 'climate', 'report', 'gain', 'sick', 'system', '@ofa', 'mark', 'policy', 'claim', 'financial', 'miami', 'editorial', 'board', 'doyourjob', 'supporter', '@flotus', 'ensure', 'access', 'decade', 'generation', \"don't\", 'garland', 'overcome', 'recent', 'carbon', 'pollution', '—president', 'individual', 'remain', 'qualified', 'deadline', 'vulnerable', 'administration', 'consumer', 'economic', 'unique', 'extend', 'streak', 'growth', 'icymi', 'historic', 'cost', 'technology', 'agreement', 'vacancy', 'democracy', 'side', 'leadonleave', 'congress', 'senator', 'nominee', 'fairly', 'income', 'poverty', 'praise', 'unprecedented', 'seek', 'broken', 'threaten', 'highly', 'pressure', 'sacred', 'responsibility', 'experience', 'leadership', 'nations', 'general', 'basic', 'partisan', 'ii', 'sen.', 'mile', '2016', 'ignore', 'constitutional', 'u.s.', 'solar', 'scotus', '⬇', 'large', 'vice', 'biden', 'meaningful', '@nytime', 'sea', 'flood', 'few', 'solve', 'unemployment', 'jobs', 'august', 'dedicate', 'solution', 'ofa', '@senatemajldr', 'federal', 'truly', 'organize', 'director', 'restore', 'prosperity', 'consequence', 'evidence', 'standard', 'duty', 'truck', 'sense', 'guarantee', 'obstruct', 'reminder', 'major', 'critical', 'essential', 'progressive', 'travel', 'extreme', 'cause', 'underscore', 'july', 'private', 'sector', 'organizer', 'plant', 'weaken', '0', 'republicans', '🎶', '@vp', 'republican', 'prevent', 'aside', 'minimum', 'raisethewage', 'crisis', 'reform', 'bipartisan', 'by', 'measure', 'confirmation', 'majority', 'op', '@wsj', 'remark', 'town', 'discussion', '@abc', 'memorial', 'police', 'dallas', 'boost', 'spending', 'slow', 'overwhelming', 'ruling', 'tackle', 'demand', 'prevention', 'd.c.', 'mayor', 'council', 'reaffirm', 'strike', 'discrimination', 'solidarity', 'ongoing', 'immigration', 'grassroots', 'struggle', 'term', 'immigrationaction', 'merrick', 'park', 'inform', 'timely', 'deficit', 'secretary', 'tpp', 'annual', 'increase', 'loud', 'calm', 'seven', 'remembrance', 'commander', '✓', 'completely', 'overtime', 'despite', 'protection', 'ohio', 'democrats', 'forum', 'key', 'strengthen', 'transparency', 'michigan', 'obstructionist', 'poll', 'denier', 'gas', 'constitution', 'june', 'criminal', 'unfair', 'industry', 'consideration', 'trillion', 'gap', 'a.m.', 'proposal', 'century', 'currently', 'flight', 'tickets', 'participate', 'blessed', 'christians', 'urge', 'approval', 'february', 'panel', 'canada', 'committee', 'delay', 'investment', 'natural', 'desire', 'january', 'recovery', '@theellenshow', 'commit', 'environment', 'overdue', 'budget', 'funding', 'creation', 'importance', 'stopgunviolence', '@facebook', 'attempt', 'waste', 'repeal', 'advance', 'period', 'crime', 'prison', 'study', '21st', 'encourage', 'prepared', 'auto', 'madeinamerica', 'detroit', 'diplomacy', 'secure', 'irandeal', 'iran', 'vision', 'reject', 'bigotry', 'form', 'louisiana', 'race', 'pacific', 'partnership', 'leadontrade', 'troop', 'arizona', 'valley', 'washington', 'thrive', 'collegeopportunity', 'training', 'priority', 'union', '@cnn', 'alaska', 'contribution', 'speed', 'briefing', 'aim', 'unitedonclimate', 'ceremony', 'pentagon', 'local', 'wisconsin', 'amendment', 'dosomething', 'terrorism', 'undermine', 'turkey', 'tennessee', 'limited', 'ofafallsummit', 'vital', 'proof', 'ship', 'lower', 'eliminate', 'negotiation', '80', 'taxpayer', 'applaud', 'drug', 'abuse', 'sale', 'prisoner', 'celebration', 'representative', 'recently', 'manufacturing', 'governor', '@whitehouse', 'die', 'lift', 'shutdown', 'tucson', 'joint', 'extraordinary', 'pledge', 'earlier', 'iowa', 'value', 'universal', 'foreign', 'non', 'avoid', 'negative', 'problem', 'information', 'favor', 'illegal', 'marines', 'flag', 'cuba', 'voting', 'provide', '50th', 'conflict', 'oppose', 'respond', 'weak', 'those', 'sanction', 'violation', 'without', 'type', 'program', 'pursue', 'comprehensive', 'proclaim', 'mistake', 'approach', 'effective', 'ability', 'u.n.', 'peaceful', 'iraq', 'committed', 'advantage', 'disability', 'presence', 'tolerate', 'rid', 'latinos', 'department', 'over', 'convention', 'housing', 'bless', '17', 'acaworks', 'remarkable', 'hawaii', 'quickly', 'failure', 'medical', '19', 'epa', 'carolina', '200', 'resource', 'courage', 'brief', 'glory', 'armed', 'forces', 'israel', 'rhetoric', 'homeland', 'era', 'enforcement', 'jersey', '@potu', 'elect', 'accountable', 'anger', 'alliance', 'presidency', 'edit', 'conversion', 'understanding', 'patient', '2013', 'jump', 'ground', 'interest', 'bridge', 'modern', '18', 'opposition', 'position', 'cleveland', 'selma50', 'marchon', 'dignity', 'army', 'meaning', 'congressional', '@dhsgov', 'lawmaker', 'isil', 'countdown', 'premium', 'itsonus', '2014', 'agenda', 'next', 'kansas', 'americaleads', 'generosity', 'infrastructure', 'development', 'ceo', 'owe', 'link', 'salute', '9:00', 'cybersecurity', 'connect', 'uniform', 'express', 'preserve', 'blessing', 'during', 'moral', 'tired', 'pardon', 'tool', 'authority', 'necessary', 'latino', 'authorize', 'accountability', 'transform', 'rick', 'medium', 'veterans', 'voter', 'anymore', 'none', '@epa', 'owner', 'renew', 'marine', 'storm', 'minister', 'condemn', 'culture', 'passage', 'guide', 'burden', 'confront', '@washingtonpost', '@savagexfenty', 'worldwide', 'sis', 'cia', 'tbh', '@voguemagazine', '😍', '@fentybeauty', 'saudi', 'arabia', '🇸', '🇦', 'collection', '✨', '🏿', '💪', '@sephora', '@harveynichol', 'dat', '🇹', 'fentyxpuma', 'gang', '🇬', '🇧', '🇺', '@emmanuelmacron', 'france', '🇫', '🇷', 'shade', 'mattemoiselle', 'dem', 'doe', '💋', 'fenty', 'stunna', 'af', '@yusefhairnyc', '@inezandvinoodh', '👀', 'da', 'shortly', '🤷', 'paint', 'pt', 'galaxycollection', 'edition', '👑', 'fam', '⚓', 'university', 'horrific', '@puma', 'situation', '@realdonaldtrump', '----&gt', 'suffering', '@claralionelfdn', 'ultimate', 'horrible', '@ellemagazine', 'moscow', 'passion', 'germany', '🇪', '🇨', '--&gt', '➡', '—&gt', 'soul', 'innocent', '😳', 'parih', '@billboard', '🎈', '🎉', 'thecreeper', 'design', 'wing', 'dis', 'tragic', '@tidalhifi', 'tix', 'brooklyn', 'merch', 'vip', '@mtv', '🎨', 'wit', '@wmag', 'stock', 'antiworldtour', 'click', '@vevo', 'itune', '22', '7th', 'vevo', 'lastnight', 'navyrdie', '@spotify', '---&gt', 'diamondball', '@lionelrichie', 'presale', 'select', 'phuck', 'ill', 'brazil', 'are', '-----&gt', 'riri', 'bbhmmvideo', '@applemusic', 'bbhmm', 'info', 'rih', 'shit', 'fuck', 'r8', '@iheartradio', '💘', 'tremendous', 'dennisleupold', 'korea', 'charity', '👏', 'again', 'majesty', 'heauxm', 'rihpost', 'barbados', 'nigga', 'very', 'bravo', 'evening', 'forest', 'rogue', 'rogueman', 'independence', 'barbado', 'phuckin', 'your', '1love', 'murder', 'tho', 'many', '@rorreyfenty', 'kinda', 'dc', '@noellaalstrom', 'behavior', 'tush', 'cuts', 'email', '😩', 'balmain', 'cr', 'yas', 'fav', 'mueller', 'counter', '@jennnrosale', 'yea', '@mforde11', 'fave', 'pain', 'bye', 'leak', 'iranian', 'defense', 'wyd', 'italy', 'thuglife', '@gnlstudio', 'generous', 'buddy', 'audition', 'believer', 'ig', '@leleboo246', 'catfish', 'iheartrihanna', 'boo', 'ur', 'adamselman', 'venezuela', 'rip', 'difficult', 'unapologetic', 'peter', 'heaux', 'ririheartsmac', 'az', 'philippines', 'whatnow', 'diamondsworldtour', 'dwt', 'rihannaforriverisland', '@gnlstudios', 'greece', 'takeoff', 'mac', 'sydney', 'pouritupvideo', 'pour', 'pouritup', 'forgive', 'rihverisland', 'thailand', 'nom', 'clique', 'indian', 'alert', 'throwbackriri', 'niggaz', 'rainbow', 'glam', 'sweden', 'easily', 'poland', 'honey', 'ratedr', 'nasty', 'remix', '777tour', 'museum', 'montreal', 'radical', 'exit', 'mail', 'we', 'toronto', 'universe', 'dopedealershit', 'times', 'dope', 'dn', '👊', 'fake', 'complex', 'floor', 'moon', 'mercy', 'ppl', 'mo', 'htc', 'vladimir', 'evil', 'patriot', 'must', 'johnson', 'cindy', 'assad', 'regime', 'f', 'russia', 'meddling', 'withdraw', 'syria', 'aggression', '@deptofdefense', 'uss', 'pilot', '@azcentral', '@dougducey', 'enhance', 'arizonans', '@dback', '@cindymccain', 'concern', 'gop', 'republic', 'declare', '@meghanmccain', '@theview', 'kosovo', 'colleague', \"imp't\", 'sadden', 'successful', 'afghanistan', 'wasteful', 'disturb', '@ap', 'admin', '@usnavy', 'flee', 'beardown', '45', 'wwii', 'distinguished', 'naval', 'sergei', 'torture', 'capability', 'humanitarian', 'aluminum', 'trail', 'nato', 'rio', 'salado', 'vietnam', 'trafficking', 'yr', 'navajo', 'kremlin', 'troll', 'northkorea', 'readiness', '@azcardinal', '@larryfitzgerald', 'slaughter', 'faithful', 'cyber', 'democratic', 'pres', 'hanoi', 'simply', 'secdef', 'mattis', 'daca', 'posture', 'fbi', 'beginning', 'nafta', 'sasc', 'witness', 'corruption', 'a-10', 'loss', 'aboard', 'cooperation', 'pleased', '@jeffflake', 'closely', 'lake', \"gov't\", 'journalist', 'reporting', 'amb', 'injure', 'missile', 'opioid', '@asu', 'pearl', 'sow', 'islamic', 'ukraine', '@navalacademy', 'flake', 'russians', 'magnitsky', 'approve', 'enemy', 'fy18ndaa', 'khan', 'terrorist', 'bravery', 'fmr', '@mactxpress', \"fed'l\", 'lack', 'boot', 'aircraft', '@usairforce', 'promote', 'humanity', 'sec', 'civilian', 'dback', '@reuter', '@usatoday', '.@dcexaminer', '.@ap', 'capitol', \"intro'd\", 'prgm', 'conduct', 'investigation', 'request', '→', 'cc', 'jonesact', 'anthem', 'operation', 'fwd', 'dialogue', 'insult', 'abe', 'japan', 'va', 'amdt', 'isis', 'defeat', 'concerned', 'agency', 'strongly', 'amid', 'divide', '@foxnew', '@uofa', 'wk', '@facethenation', 'reg', 'testify', 'dept', 'chairman', '@cbsnew', 'sequestration', 'kara', 'murza', 'camp', 'capable', 'terminate', 'kerry', 'monitor', 'disgraceful', '@lindseygrahamsc', 'inspection', 'tokyo', 'egypt', 'practice', 'correct', 'assistance', 'hike', 'adm', 'abandon', 'racist', 'vet', 'unite', 'steve', 'worthy', 'probe', 'firm', '@broomheadshow', '@kfyi', 'pence', 'fy17ndaa', 'whistleblower', 'stmt', 'canyon', 'strategic', 'daily', 'healthcare', 'humility', 'syrian', 'dems', 'montenegro', 'xi', 'impt', 'delegation', 'advisor', 'pakistan', 'mtg', 'exec', 'asia', 'cmte', 'mourn', '@timkaine', 'comey', 'intel', 'sen', 'badly', 'memorialday', 'gen', \"nat'l\", 'afternoon', '@msnbc', 'endorse', 'investigate', 'clapper', 'jong', 'pleasure', 'hoax', 'separate', 'choice4vet', 'gorsuch', 'cont', 'lawyer', 'seed', 'religious', 'bully', 'democrat', 'refugee', 'mohave', 'rocket', 'muslims', 'cabinet', '@foxandfriend', 'aleppo', 'sessions', 'chat', 'fraud', 'donald', 'ballot', 'flagstaff', 'prescott', 'payment', 'proclamation', 'regulation', 'colorado', 'blame', 'clinton', 'hillary', 'sanctuary', 'division', 'cedarfire', 'false', 'paul', 'barrier', 'admit', 'christ', 'sinner', 'neighbour', 'authentic', 'gospel', 'wealth', 'church', 'constantly', 'holiness', 'hunger', 'difficulty', 'forgiveness', 'feast', 'lent', 'spiritual', 'sacrament', 'reconciliation', 'tenderness', 'gaze', 'merciful', 'accompany', 'missionary', 'disciple', 'heal', 'fruit', 'entrust', 'inclusive', 'kingdom', 'enthusiasm', 'nature', 'migrant', 'centre', 'intention', 'comfort', 'indifference', 'diversity', 'jubilee', 'laudatosi', 'elderly', 'primary', 'garden', 'ng', 'prayforpeace', 'rio2013', 'jmj', 'angry', 'phony', 'witch', 'hunt', 'collusion', 'etc', 'failing', 'u.s.a.', 'maga', 'cnn', 'classified', '.@flotus', 'dishonest', 'crooked', 'media', 'mccabe', 'hopefully', 'leaker', 'rig', 'a.g.', 'luther', 'our', 'j.', 'candidate', 'responders', 'pennsylvania', 'oval', 'politically', 'dnc', 'ivanka', 'quit', 'schumer', 'barack', 'dow', 'optimism', 'disrespect', 'fakenews', '📸', '🇵', 'bernie', '🎥', 'americafirst', 'corker', 'newspaper', 'fema', 'endorsement', '☑', 'bedminster', '🇱', '🏈', '@bloodpop', 'purposetourstadium', 'purposetour', 'belieber', 'purposeworldtour', '@martingarrix', 'coldwater', '@scooterbraun', '@diplo', '@skrillex', '🏻', '😜', 'loveyourself', '@carlyraejepsen', 'whatdoyoumean', 'whereareunow', '✈', 'eveningwithjb', '@halsey', 'purposethemovement', 'illshowyou', 'nov13', 'preorderpurpose', 'purposealbum', '@astrid_nv', '@iammarleydia', '@aijenpoo', '@domesticworker', '🍕', 'tuition', '-h', '—hillary', '—@potu', '—@flotus', '—@flotu', 'divisive', '—donald', '47246', 'temperament', 'unfit', 'debatenight', 'vpdebate', '—@joebiden', 'demsinphilly', '🚨', '✌', '🏼\\u200d', '😑', '@kpcollection', '💃', '👁', '💅', '👠', '☝', '👋', '@americanidol', '❗', '😔', '🌴', '🌈', '🌟', '🐶', '🙅', '🎟', '@covergirl', '💄', 'witnessthetour', '⤵️', '🇿', 'fbf', '🎄', 'katy', '@sofifii', '🎅', '🎃', 'perry', '👼', '🇳', 'bb', 'swishswish', '🙍', 'kpwww', '-teamkp', 'kp', '@shannonwoodward', 'pls', '🍒', 'chainedtotherhythm', '⛓', 'appstorechat', 'theprismaticworldtour', '˚', 'thisishowwedo'])\n"
     ]
    }
   ],
   "source": [
    "# List of words in model.\n",
    "vocab = model.wv.vocab.keys()\n",
    "\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('michelle', 0.6871036291122437), ('difference', 0.6757922172546387), ('—@flotus', 0.6386368274688721), ('laugh', 0.6340092420578003), ('supporter', 0.6325311064720154), ('passion', 0.6190457344055176), ('invite', 0.609879732131958), ('quit', 0.6039540767669678), ('—@flotu', 0.6027598977088928), ('how', 0.6005479693412781)]\n",
      "0.928660143849258\n",
      "0.7308674041490782\n",
      "0.5728832561326569\n",
      "🍕\n",
      "forgiveness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['crooked', 'honest'], negative=['dishonest']))\n",
    "\n",
    "# Similarity is calculated using the cosine, so again 1 is total\n",
    "# similarity and 0 is no similarity.\n",
    "print(model.wv.similarity('💄', '👠'))\n",
    "print(model.wv.similarity('repeal', 'delay'))\n",
    "print(model.wv.similarity('laugh', 'joy'))\n",
    "\n",
    "# One of these things is not like the other...\n",
    "print(model.doesnt_match(\"💪 🙌 🍕 👏\".split()))\n",
    "print(model.doesnt_match(\"phony dishonest crooked forgiveness\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
