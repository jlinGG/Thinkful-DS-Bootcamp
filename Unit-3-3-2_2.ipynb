{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 3.3.2 Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving on OLS\n",
    "\n",
    "When we introduced regression, we said that the model fit is determined by minimizing the sum of the squared differences between the predicted and actual values. This is _Ordinary Least Squares_:\n",
    "\n",
    "$$\\sum_{i=1}^n(y_i-(\\alpha+\\beta x_i))^2$$\n",
    "\n",
    "It just so happens, however, that we can get more accurate *predictions* by modifying this cost function in various ways.  One way to think of this is that the OLS cost function optimizes variance explained *in the training set.*  Ridge and lasso regressions are two examples of modifying this cost function. They lead to models that optimize variance explained *in the test sets.*  Generally our goal is to make a model that tells us about the world (and not just our training sample), so ridge and lasso solutions are useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression\n",
    "\n",
    "**Ridge regression** minimizes this cost function:\n",
    "\n",
    "$$\\sum_{i=1}^n(y_i-(\\alpha+\\beta x_i))^2+\\lambda\\sum_{j=1}^p\\beta_j^2 $$\n",
    "\n",
    "Comparing this cost function to the OLS cost function above, you can see it consists of the OLS function with a new part to the right:\n",
    "\n",
    "$$\\lambda\\sum_{j=1}^p\\beta_j^2 $$\n",
    "\n",
    "**This new part imposes a penalty for large coefficients.**  It represents the sum of the square of all model coefficients (numbered 1 through $p$), multiplied by the regularization parameter $\\lambda$.  As $\\lambda$ gets larger, the penalty for coefficient size also gets larger, and the solution that minimizes the cost function will by necessity have smaller coefficient estimates.  Regularization based on the sum of the squared weights is also called \"**L2 regularization**\".\n",
    "\n",
    "[**Quick check**: If the convention is to call the regularization parameter \"*lambda*\" ($\\lambda$), why does SKlearn call it \"*alpha*\"?  Hint: It's the same reason why you shouldn't name your own variables in Python things like \"mean\".]\n",
    "\n",
    "**The core principle behind ridge regression is that, as models become increasingly complex and features correlate with one another more and more (become _multicolinear_), coefficients arrived at by OLS become increasingly large.** This is a sign that the model is incorporating too much variance from the dataset â€“ in other words, overfitting. Ridge regression is a model variance minimizer and works to keep that from happening. For a deep dive into the underlying math and origin of the term \"ridge regression\" see this detailed [Stack Exchange answer](http://stats.stackexchange.com/questions/151304/why-is-ridge-regression-called-ridge-why-is-it-needed-and-what-happens-when).\n",
    "\n",
    "Here's an example of coefficient inflation, using some patterns of defaulting on credit accounts. You can [read more about this data here](http://vincentarelbundock.github.io/Rdatasets/doc/ISLR/Default.html).\n",
    "\n",
    "First, we'll build an OLS multivariate linear regression model predicting defaults using all the features in the data. Then, we'll create some new correlated features, add them to the model, and see what that does to the size of the original coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load air quality data, drop the index column and any missing data columns.\n",
    "df = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/ISLR/Default.csv'\n",
    ").iloc[:, 1:].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student      balance        income\n",
       "0      No      No   729.526495  44361.625074\n",
       "1      No     Yes   817.180407  12106.134700\n",
       "2      No      No  1073.549164  31767.138947\n",
       "3      No      No   529.250605  35704.493935\n",
       "4      No      No   785.655883  38463.495879"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode strings to numeric.\n",
    "df['default'] = np.where(df['default'] == 'Yes', 1, 0)\n",
    "df['student'] = np.where(df['student'] == 'Yes', 1, 0)\n",
    "names = df.columns\n",
    "df = pd.DataFrame(preprocessing.scale(df), columns=names)\n",
    "\n",
    "# Define the training and test sizes.  Half of dataset for testing, half for training\n",
    "trainsize = int(df.shape[0] / 2)\n",
    "df_test = df.iloc[trainsize:, :].copy()\n",
    "df_train = df.iloc[:trainsize, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared simple model:\n",
      "0.573878496272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/scipy/linalg/basic.py:1018: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Set up the regression model to predict defaults using all other\n",
    "# variables as features.\n",
    "regr1 = linear_model.LinearRegression()\n",
    "Y_train = df_train['income'].values.reshape(-1, 1)\n",
    "X_train = df_train.loc[:, ~(df_train.columns).isin(['income'])]\n",
    "regr1.fit(X_train, Y_train)\n",
    "print('\\nR-squared simple model:')\n",
    "print(regr1.score(X_train, Y_train))\n",
    "\n",
    "#Store the parameter estimates.\n",
    "origparams = np.append(regr1.coef_, regr1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared complex model:\n",
      "0.573973445206\n"
     ]
    }
   ],
   "source": [
    "# Make new features to capture potential quadratic and cubic relationships\n",
    "# between the features.\n",
    "df_train['balance_student'] = df_train['balance'] * df_train['student']\n",
    "df_train['balance_default'] = df_train['balance'] * df_train['default']\n",
    "df_train['student_default'] = df_train['student'] * df_train['default']\n",
    "df_train['balance_sqrt'] = (df_train['balance'] + 100) ** .5\n",
    "df_train['balance2'] = (df_train['balance'] + 100) ** 2\n",
    "df_train['balance3'] = (df_train['balance'] + 100) ** 3\n",
    "\n",
    "# Re-run the model with the new features.\n",
    "regrBig = linear_model.LinearRegression()\n",
    "X_train2 = df_train.loc[:, ~(df_train.columns).isin(['income'])]\n",
    "regrBig.fit(X_train2, Y_train)\n",
    "print('\\nR-squared complex model:')\n",
    "print(regrBig.score(X_train2, Y_train))\n",
    "\n",
    "# Store the new parameter estimates for the same features.\n",
    "newparams = np.append(\n",
    "    regrBig.coef_[0,0:(len(origparams)-1)],\n",
    "    regrBig.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameter Estimates for the same predictors for the small model and large model:\n",
      "[[0.014 -0.004]\n",
      " [-0.759 -0.759]\n",
      " [0.000 4157.864]\n",
      " [-0.001 553434.239]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nParameter Estimates for the same predictors for the small model '\n",
    "      'and large model:')\n",
    "compare = np.column_stack((origparams, newparams))\n",
    "prettycompare = np.array2string(\n",
    "    compare,\n",
    "    formatter={'float_kind':'{0:.3f}'.format})\n",
    "print(prettycompare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at that intercept (last line)!  The R-squared value barely increased, but even so the inflation of the parameters suggests that the gain is due to overfitting.  Let's apply the model to the test set and find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R-squared simple model:\n",
      "0.56306979225\n",
      "\n",
      "R-squared complex model:\n",
      "0.563023952732\n"
     ]
    }
   ],
   "source": [
    "# Test the simpler model with smaller coefficients.\n",
    "Y_test = df_test['income'].values.reshape(-1, 1)\n",
    "X_test = df_test.loc[:, ~(df_test.columns).isin(['income'])]\n",
    "print('\\nR-squared simple model:')\n",
    "print(regr1.score(X_test, Y_test))\n",
    "\n",
    "# Test the more complex model with larger coefficients.\n",
    "df_test['balance_student'] = df_test['balance'] * df_test['student']\n",
    "df_test['balance_default'] = df_test['balance'] * df_test['default']\n",
    "df_test['student_default'] = df_test['student'] * df_test['default']\n",
    "df_test['balance_sqrt'] = (df_test['balance'] + 100) ** .5\n",
    "df_test['balance2'] = (df_test['balance'] + 100) ** 2\n",
    "df_test['balance3'] = (df_test['balance'] + 100) ** 3\n",
    "\n",
    "# Re-run the model with the new features.\n",
    "X_test2 = df_test.loc[:, ~(df_test.columns).isin(['income'])]\n",
    "print('\\nR-squared complex model:')\n",
    "print(regrBig.score(X_test2, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup- the more complex model actually fits worse.  The differences here are quite small, but that isn't always the case.  What happens if we apply ridge regression to this situation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57387391644\n",
      "[  1.36988466e-02  -7.57859433e-01  -3.25298557e-04]\n",
      "0.573946428961\n",
      "\n",
      "Parameter Estimates for the same predictors for the small model and large model:\n",
      "[[0.014 -0.002]\n",
      " [-0.758 -0.757]\n",
      " [-0.000 0.048]]\n"
     ]
    }
   ],
   "source": [
    "# Fitting a ridge regression model. Alpha is the regularization\n",
    "# parameter (usually called lambda). As alpha gets larger, parameter\n",
    "# shrinkage grows more pronounced. Note that by convention, the\n",
    "# intercept is not regularized. Since we standardized the data\n",
    "# earlier, the intercept should be equal to zero and can be dropped.\n",
    "\n",
    "ridgeregr = linear_model.Ridge(alpha=10, fit_intercept=False) \n",
    "ridgeregr.fit(X_train, Y_train)\n",
    "print(ridgeregr.score(X_train, Y_train))\n",
    "origparams = ridgeregr.coef_[0]\n",
    "print(origparams)\n",
    "\n",
    "ridgeregrBig = linear_model.Ridge(alpha=10, fit_intercept=False)\n",
    "ridgeregrBig.fit(X_train2, Y_train)\n",
    "print(ridgeregrBig.score(X_train2, Y_train))\n",
    "newparams = ridgeregrBig.coef_[0, 0:len(origparams)]\n",
    "\n",
    "print('\\nParameter Estimates for the same predictors for the small model'\n",
    "      ' and large model:')\n",
    "compare = np.column_stack((origparams, newparams))\n",
    "prettycompare = np.array2string(\n",
    "    compare,\n",
    "    formatter={'float_kind':'{0:.3f}'.format})\n",
    "print(prettycompare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a detailed discussion of why the intercept is not regularized, see [this entry on Stack Exchange](http://stats.stackexchange.com/questions/86991/reason-for-not-shrinking-the-bias-intercept-term-in-regression).\n",
    "\n",
    "The difference in magnitude for parameters in the training set is much smaller â€“ no parameter explosion here. Let's check the implications for the fit of the models on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.563108876308\n",
      "0.563180432393\n"
     ]
    }
   ],
   "source": [
    "print(ridgeregr.score(X_test, Y_test))\n",
    "print(ridgeregrBig.score(X_test2, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, the model that worked a little better on the training set also works a little better on the test set. Again, these differences are small and don't matter much here, but in real life much larger differences can happen. Ridge regression is an excellent tool to reach for whenever you have many correlated parameters, or when you start to see parameter estimates inflate as the R-square estimate goes up, suggesting overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization parameter: Ridge\n",
    "\n",
    "Earlier, we set the regularization parameter $\\lambda=10$.  In ridge regression, the regularization parameter $\\lambda$ can take any value greater than 0.  The best way to choose an optimal regularization parameter is through cross-validation, checking which parameter gives the most consistent results across training and test sets.  Here is an illustration of how the parameter values in the income model vary as alpha goes up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAECCAYAAAAYfWtSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCswISFJgRkCSAjMCkhTYB2ghadcNMdaxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10af3d630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Store estimates.\n",
    "estimates = np.append(ridgeregrBig.coef_, [10])\n",
    "\n",
    "# Storing legend information.\n",
    "labels = []\n",
    "\n",
    "#Run the model for many alphas.\n",
    "for lambd in range(1, 50, 2):\n",
    "    ridgeregrBig = linear_model.Ridge(alpha=lambd, fit_intercept=False)\n",
    "    ridgeregrBig.fit(X_train2, Y_train)\n",
    "    estimates = np.row_stack((\n",
    "        estimates,\n",
    "        np.append(ridgeregrBig.coef_,[lambd])))\n",
    "\n",
    "# Make the data pretty.\n",
    "estimates_df = pd.DataFrame(\n",
    "    estimates,\n",
    "    columns=list(X_train2.columns) + ['lambda'])\n",
    "estimates_df.sort_values(by='lambda', inplace=True, ascending=True)\n",
    "\n",
    "# Leave out the 'student' variable.\n",
    "# It has very high values and throws off our plot's scale.\n",
    "varstoplot = list(estimates_df.columns[:9,])\n",
    "varstoplot.remove('student')\n",
    "\n",
    "# Plot a line for each parameter.\n",
    "for var in varstoplot:\n",
    "    plt.plot(estimates_df['lambda'], estimates_df[var])\n",
    "    labels.append(var)\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('Parameter estimate size')\n",
    "plt.legend(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do you read this graph?\n",
    "Is it, we pick the lambdas where the parameters are the smallest?  What is the advantage of picking smaller or bigger lambdas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a truly deep-dive into the math behind ridge regression, check out these lecture slides on [Ridge Regression](http://www.few.vu.nl/~wvanwie/Courses/HighdimensionalDataAnalysis/WNvanWieringen_HDDA_Lecture23_RidgeRegression_20172018.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 3.3.3 Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression shrinks parameter estimates, but the estimates never reach exactly 0.  **LASSO** (Least Absolute Shrinkage and Selection Operator), on the other hand, is a model optimization mechanic that works by trying to **force small parameter estimates to be equal to zero, effectively dropping them from the model.**  This can prevent overfitting, and also works as an **embedded feature selection method.**  Lasso is extremely handy when you are dealing with thousands or hundreds of thousands of predictors and need to optimize processor time, or when you want to arrive at a simpler solution that is easier to interpret.\n",
    "\n",
    "The cost function to minimize for lasso is _very similar_ to the cost function minimized for ridge. Can you spot the difference?\n",
    "\n",
    "$$\\sum_{i=1}^n(y_i-(\\alpha+\\beta x_i))^2+\\lambda\\sum_{j=1}^p|\\beta_j| $$\n",
    "\n",
    "The difference is that rather than penalizing by the sum of *squared* coefficients as ridge does, lasso penalizes by the sum of the ***absolute values* of the coefficients.**  This means the penalty doesn't increase as swiftly with coefficient size.  Regularization based on the sum of the absolute weights is also called \"**L1 regularization**\".\n",
    "\n",
    "Why would penalizing with the sum of the absolute values of coefficients lead to a solution with zero estimates for some parameters, while penalizing with the sum of the squares of coefficients does not?  It all comes down to derivatives.\n",
    "\n",
    "We encountered derivatives briefly during an earlier assignment on the gradient descent algorithm.  You may recall that a partial derivative represents the sensitivity of one quantity to changes in another quantity.  In the case of both ordinary least squares regression and ridge regression, the derivative used to find the optimal solution is the partial derivative of the cost function relative to the coefficients in $\\beta$:\n",
    "\n",
    "$$\\frac{\\partial}{\\partial\\beta}$$\n",
    "\n",
    "Unfortunately, that won't work for lasso. While we can calculate a derivative for most of the values of $x$ in lasso, there is no derivative where $x=0$.  You can imagine this as our multi-dimensional surface made up of gradients having a big hole in it (the technical term for the hole is a \"*discontinuity*\"). If the gradient descent algorithm calculates a value that falls in the \"hole\", it has no idea where to go next.  The model \"fails to converge\". In other words, it fails to arrive at an optimal solution.\n",
    "\n",
    "^^ **I don't understand this...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Lasso: Coordinate Descent Algorithm\n",
    "\n",
    "Since basing modeling strategy on a surface with a hole in it is obviously not ideal, lasso regression models are optimized using a **coordinate descent algorithm** rather than a gradient descent algorithm.  Coordinate descent works like this:\n",
    "\n",
    "Pick some starting values for $\\beta$, often $\\beta=0$. \n",
    "\n",
    "For each feature $j$ in $\\beta$:\n",
    "* Predict the outcome using all features except for $j$.  \n",
    "* Look at how the residuals from the model using $\\beta_{-j}$ (all betas except $j$) correlate with feature $j$. This correlation is called $\\rho_j$.  \n",
    "* If the correlation falls within an area enclosing 0 defined by $\\lambda$, set $\\beta_j=0$. (called *soft threshholding*)\n",
    "* If $\\rho_j < \\frac{\\lambda}2$ set $\\beta_j$ equal to $\\rho_j + \\frac{\\lambda}2$\n",
    "* If $\\rho_j > \\frac{\\lambda}2$ set $\\beta_j$ equal to $\\rho_j - \\frac{\\lambda}2$\n",
    "\n",
    "This will iterate through all features 1 through $j$ on each cycle, then begin again.  Alternatively, the algorithm can be set to choose to exclude a feature at random each iteration, rather than cycling through all features.  Each time a feature is checked, it will shrink a bit from the previous time (unless the feature is already set to 0, in which case it will remain 0).\n",
    "\n",
    "Continue until the maximum difference between parameter estimates in the previous cycle and the current cycle is less than a pre-determined threshold $tol$.  For SKlearn, $tol$ defaults to 0.0001.\n",
    "\n",
    "**To summarize:** Lasso works by iteratively fitting a model to the data while excluding one of the features.  It then checks how well the model reproduces the data, and if the model fit is good enough (with \"good enough\" determined by $\\lambda$) then the excluded feature is deemed unnecessary and its $\\beta$ is set to zero, effectively excluding it from the model. Otherwise, the excluded feature's $\\beta$ is set using a combination of the correlation of the feature with the model residuals ($\\rho_j$) and $\\frac{\\lambda}2$ and a new iteration begins, using the newly-computed $\\beta$ for the previously-excluded feature and excluding a new feature.  This continues until the change in $\\beta$ is less than a pre-determined threshold.\n",
    "\n",
    "Hopefully this demonstrates how lasso can both create overfitting-protection through shrinkage and create sparsity (many parameters set to 0) through feature selection.  Let's see it at work, using the same dataset as previously.\n",
    "\n",
    "\n",
    "**Why does Lasso regression use smaller lambdas (alphas)???**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RÂ² for the model with few features:\n",
      "0.450062579301\n",
      "\n",
      "Parameter estimates for the model with few features:\n",
      "[-0.         -0.40657726 -0.          0.00114596]\n",
      "\n",
      "RÂ² for the model with many features:\n",
      "0.443633767129\n",
      "\n",
      "Parameter estimates for the model with many features:\n",
      "[  0.00000000e+00  -3.89351238e-01   0.00000000e+00  -0.00000000e+00\n",
      "   0.00000000e+00  -0.00000000e+00   0.00000000e+00  -2.77688887e-04\n",
      "  -7.09158792e-07   3.48711577e+00]\n"
     ]
    }
   ],
   "source": [
    "# Small number of parameters.\n",
    "lass = linear_model.Lasso(alpha=.35)\n",
    "lassfit = lass.fit(X_train, Y_train)\n",
    "print('RÂ² for the model with few features:')\n",
    "print(lass.score(X_train, Y_train))\n",
    "origparams = np.append(lassfit.coef_, lassfit.intercept_)\n",
    "print('\\nParameter estimates for the model with few features:')\n",
    "print(origparams)\n",
    "\n",
    "# Large number of parameters.\n",
    "lassBig = linear_model.Lasso(alpha=.35)\n",
    "lassBig.fit(X_train2, Y_train)\n",
    "print('\\nRÂ² for the model with many features:')\n",
    "print(lassBig.score(X_train2, Y_train))\n",
    "origparams = np.append(lassBig.coef_, lassBig.intercept_)\n",
    "print('\\nParameter estimates for the model with many features:')\n",
    "print(origparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking predictive power using the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.445532251512\n",
      "0.438046634591\n"
     ]
    }
   ],
   "source": [
    "print(lass.score(X_test, Y_test))\n",
    "\n",
    "print(lassBig.score(X_test2, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization parameter: Lasso\n",
    "\n",
    "The $\\lambda$ for lasso can vary between 0 (no penalty, acts like OLS) and infinity.  If $\\lambda$ is too large, all parameters will be set to zero.  \n",
    "\n",
    "Create a plot below of how $R^2$ varies across different values of $\\lambda$ for ridge and lasso regression. Use logic and code similar to the ridge regression demonstration above, and base your plot on the X_train2 feature set.\n",
    "\n",
    "Do lasso and ridge yield the same $R^2$ for a given lambda value?\n",
    "\n",
    "Submit your work and discuss the results with your mentor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEBCAYAAAC0WehTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10aefd400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Store estimates.\n",
    "estimates = np.append(lassBig.coef_, [10])\n",
    "\n",
    "# Storing legend information.\n",
    "labels = []\n",
    "\n",
    "#Run the model for many alphas.\n",
    "for lambd in range(1, 50, 2):\n",
    "    lassregrBig = linear_model.Lasso(alpha=lambd, fit_intercept=False)\n",
    "    lassregrBig.fit(X_train2, Y_train)\n",
    "    estimates = np.row_stack((\n",
    "        estimates,\n",
    "        np.append(lassBig.coef_,[lambd])))\n",
    "\n",
    "# Make the data pretty.\n",
    "estimates_df = pd.DataFrame(\n",
    "    estimates,\n",
    "    columns=list(X_train2.columns) + ['lambda'])\n",
    "estimates_df.sort_values(by='lambda', inplace=True, ascending=True)\n",
    "\n",
    "# Leave out the 'student' variable.\n",
    "# It has very high values and throws off our plot's scale.\n",
    "varstoplot = list(estimates_df.columns[:9,])\n",
    "varstoplot.remove('student')\n",
    "\n",
    "# Plot a line for each parameter.\n",
    "for var in varstoplot:\n",
    "    plt.plot(estimates_df['lambda'], estimates_df[var])\n",
    "    labels.append(var)\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('Parameter estimate size')\n",
    "plt.legend(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ Did I do this right?\n",
    "\n",
    "Calculating $R^2$s with different lambdas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/ipykernel_launcher.py:11: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Store R^2.\n",
    "lassoBigR2 = np.append(lassBig.score(X_train2, Y_train), [10])\n",
    "ridgeBigR2 = np.append(ridgeregrBig.score(X_train2, Y_train), [10])\n",
    "\n",
    "# Storing legend information.\n",
    "labels = []\n",
    "\n",
    "#Run the model for many alphas.\n",
    "for lambd in np.arange(0,50,2):\n",
    "    lassregrBig = linear_model.Lasso(alpha=lambd, fit_intercept=False)\n",
    "    lassregrBig.fit(X_train2, Y_train)\n",
    "    lassoBigR2 = np.row_stack((\n",
    "        lassoBigR2,\n",
    "        np.append(lassregrBig.score(X_train2, Y_train),[lambd])))\n",
    "\n",
    "for lambd in np.arange(0,50,2):\n",
    "    ridgeregrBig = linear_model.Ridge(alpha=lambd, fit_intercept=False)\n",
    "    ridgeregrBig.fit(X_train2, Y_train)\n",
    "    ridgeBigR2 = np.row_stack((\n",
    "        ridgeBigR2,\n",
    "        np.append(ridgeregrBig.score(X_train2, Y_train),[lambd])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.57396614,  10.        ],\n",
       "       [  0.57397331,   0.        ],\n",
       "       [  0.57396386,   2.        ],\n",
       "       [  0.573957  ,   4.        ],\n",
       "       [  0.57395251,   6.        ],\n",
       "       [  0.57394918,   8.        ],\n",
       "       [  0.57394643,  10.        ],\n",
       "       [  0.57394396,  12.        ],\n",
       "       [  0.5739416 ,  14.        ],\n",
       "       [  0.57393927,  16.        ],\n",
       "       [  0.57393689,  18.        ],\n",
       "       [  0.57393443,  20.        ],\n",
       "       [  0.57393186,  22.        ],\n",
       "       [  0.57392916,  24.        ],\n",
       "       [  0.57392633,  26.        ],\n",
       "       [  0.57392334,  28.        ],\n",
       "       [  0.57392019,  30.        ],\n",
       "       [  0.57391688,  32.        ],\n",
       "       [  0.5739134 ,  34.        ],\n",
       "       [  0.57390974,  36.        ],\n",
       "       [  0.57390592,  38.        ],\n",
       "       [  0.57390191,  40.        ],\n",
       "       [  0.57389773,  42.        ],\n",
       "       [  0.57389337,  44.        ],\n",
       "       [  0.57388883,  46.        ],\n",
       "       [  0.5738841 ,  48.        ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgeBigR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.43633767e-01,   1.00000000e+01],\n",
       "       [  5.73938904e-01,   0.00000000e+00],\n",
       "       [  4.34046037e-03,   2.00000000e+00],\n",
       "       [  3.75518950e-03,   4.00000000e+00],\n",
       "       [  3.16242342e-03,   6.00000000e+00],\n",
       "       [  2.56239143e-03,   8.00000000e+00],\n",
       "       [  1.95521310e-03,   1.00000000e+01],\n",
       "       [  1.34055365e-03,   1.20000000e+01],\n",
       "       [  7.18413080e-04,   1.40000000e+01],\n",
       "       [  8.87913979e-05,   1.60000000e+01],\n",
       "       [ -1.51811140e-05,   1.80000000e+01],\n",
       "       [ -1.51811901e-05,   2.00000000e+01],\n",
       "       [ -1.51812743e-05,   2.20000000e+01],\n",
       "       [ -1.51813664e-05,   2.40000000e+01],\n",
       "       [ -1.51814666e-05,   2.60000000e+01],\n",
       "       [ -1.51815748e-05,   2.80000000e+01],\n",
       "       [ -1.51816910e-05,   3.00000000e+01],\n",
       "       [ -1.51818152e-05,   3.20000000e+01],\n",
       "       [ -1.51819474e-05,   3.40000000e+01],\n",
       "       [ -1.51820877e-05,   3.60000000e+01],\n",
       "       [ -1.51822359e-05,   3.80000000e+01],\n",
       "       [ -1.51823922e-05,   4.00000000e+01],\n",
       "       [ -1.51825565e-05,   4.20000000e+01],\n",
       "       [ -1.51827288e-05,   4.40000000e+01],\n",
       "       [ -1.51829091e-05,   4.60000000e+01],\n",
       "       [ -1.51830974e-05,   4.80000000e+01]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassoBigR2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression does better than lasso when lambda is set between 0 and 50.\n",
    "\n",
    "\n",
    "(Why though?  And what does mean for the analysis?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
